

# Pesquisa V7 - SoluÃ§Ãµes Finais para Tese de Doutorado

**Branch:** `pesquisa_v7`  
**Status:** Em desenvolvimento  
**Objetivo:** Implementar e comparar 3 soluÃ§Ãµes arquiteturais fundamentadas em literatura para alcanÃ§ar alta acurÃ¡cia na prediÃ§Ã£o de partiÃ§Ãµes AV1.

---

## ğŸ“š FundamentaÃ§Ã£o TeÃ³rica

### Artigos Base

1. **Chen et al. (CVPR 2024)** - "Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets"
   - **Conceito:** Parameter Efficient Tuning (PET) - congela backbone, aprende apenas modulaÃ§Ã£o
   - **Resultado:** Iguala ou supera full fine-tuning com apenas 3.5% dos parÃ¢metros
   - **AplicaÃ§Ã£o:** Resolver negative transfer (Stage 1 â†’ Stage 2)

2. **Ahad et al. (2024)** - "Ensemble Model for Breast Cancer Detection"
   - **Conceito:** Ensemble com voting-based (DenseNet121 + InceptionV3 + ResNet18)
   - **Resultado:** 99.94% acurÃ¡cia vs 99% do melhor modelo individual
   - **AplicaÃ§Ã£o:** Compensar erros individuais em classificaÃ§Ã£o hierÃ¡rquica

---

## ğŸ¯ As TrÃªs SoluÃ§Ãµes

### **SoluÃ§Ã£o 1: Conv-Adapter** (Parameter Efficient Transfer)

**Literatura:** Chen et al., CVPR 2024

**Arquitetura:**
```
Stage 1: Treina backbone + binary head (NONE vs PARTITION)
         â†“ (congela backbone)
Stage 2: Conv-Adapter (3.5% params) + 3-way head (SPLIT, RECT, AB)
         â†“ (congela backbone)
Stage 3: Conv-Adapter (3.5% params) + specialist heads
```

**Mecanismo:** `h â† h + Î±Â·Î”h` (feature modulation, nÃ£o substituiÃ§Ã£o)

**HipÃ³tese:** Congelar backbone apÃ³s Stage 1 elimina negative transfer  
**Expectativa:** Stage 2 F1: 46% â†’ 60-65%

**ImplementaÃ§Ã£o:** `v7_pipeline/conv_adapter.py`

---

### **SoluÃ§Ã£o 2: Multi-Stage Ensemble**

**Literatura:** Ahad et al., 2024

**Arquitetura:**
```
3 backbones diferentes (ResNet18, MobileNetV2, EfficientNet)
         â†“
Cada backbone tem pipeline hierÃ¡rquica completa (Stage 1â†’2â†’3)
         â†“
Soft voting em cada estÃ¡gio
```

**Mecanismo:** Weighted average de probabilidades

**HipÃ³tese:** Diversidade arquitetural compensa erros individuais  
**Expectativa:** Pipeline F1: +5-8% vs melhor modelo individual

**ImplementaÃ§Ã£o:** `v7_pipeline/ensemble.py`

---

### **SoluÃ§Ã£o 3: Hybrid (Adapter + Ensemble)** â­ **RECOMENDADO**

**Literatura:** CombinaÃ§Ã£o inovadora de Chen et al. + Ahad et al.

**Arquitetura:**
```
Backbone compartilhado (frozen apÃ³s Stage 1)
         â†“
3 Conv-Adapters com configs diferentes (reduction=4,8,4)
         â†“
Soft voting over adapter outputs
         â†“
Aplicado em TODOS os stages (Stage 2, 3-RECT, 3-AB)
```

**Vantagens:**
- âœ… Parameter efficient: ~10% trainable (vs 300% para 3 backbones)
- âœ… Negative transfer prevention (backbone frozen)
- âœ… Ensemble boosting (+1-5% F1)
- âœ… Few-shot robustness (adapters excelentes em classes raras)

**Expectativa:**
- Stage 2 F1: 46% â†’ **65-73%**
- Stage 3-AB F1: 24.5% â†’ **45-50%**
- Pipeline completo: **~70-75%**

**ImplementaÃ§Ã£o:** `v7_pipeline/hybrid_model.py`

---

## ğŸ“ Estrutura do Projeto

```
pesquisa_v7/
â”œâ”€â”€ README.md                          # Este arquivo
â”œâ”€â”€ ARCHITECTURE_V7.md                 # Diagramas arquiteturais detalhados
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 001_prepare_dataset.py         # PreparaÃ§Ã£o base (v6 dataset)
â”‚   â”œâ”€â”€ 002_prepare_stage3_datasets.py # Especialistas RECT/AB
â”‚   â”œâ”€â”€ 010_baseline_v6_reproduction.py    # Baseline comparativo
â”‚   â”œâ”€â”€ 020_train_adapter_solution.py      # SoluÃ§Ã£o 1: Conv-Adapter
â”‚   â”œâ”€â”€ 030_train_ensemble_solution.py     # SoluÃ§Ã£o 2: Ensemble
â”‚   â”œâ”€â”€ 040_train_hybrid_solution.py       # SoluÃ§Ã£o 3: HÃ­brido
â”‚   â””â”€â”€ 050_evaluate_all_solutions.py      # ComparaÃ§Ã£o final
â”‚
â”œâ”€â”€ v7_pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_hub.py              # Dataset classes (copiado v6)
â”‚   â”œâ”€â”€ losses.py                # Loss functions (copiado v6)
â”‚   â”œâ”€â”€ backbone.py              # ImprovedBackbone refatorado
â”‚   â”œâ”€â”€ conv_adapter.py          # NOVO - Conv-Adapter (Chen et al.)
â”‚   â”œâ”€â”€ ensemble.py              # NOVO - Ensemble voting (Ahad et al.)
â”‚   â”œâ”€â”€ hybrid_model.py          # NOVO - Adapter + Ensemble
â”‚   â””â”€â”€ evaluation.py            # NOVO - MÃ©tricas unificadas
â”‚
â”œâ”€â”€ logs/v7_experiments/
â”‚   â”œâ”€â”€ baseline/                # Resultados v6 reproduction
â”‚   â”œâ”€â”€ solution1_adapter/       # Conv-Adapter results
â”‚   â”œâ”€â”€ solution2_ensemble/      # Ensemble results
â”‚   â””â”€â”€ solution3_hybrid/        # Hybrid results (MELHOR ESPERADO)
â”‚
â””â”€â”€ docs_v7/
    â”œâ”€â”€ 00_README.md             # Ãndice documentaÃ§Ã£o
    â”œâ”€â”€ 01_solution1_conv_adapter.md
    â”œâ”€â”€ 02_solution2_ensemble.md
    â”œâ”€â”€ 03_solution3_hybrid.md
    â””â”€â”€ 04_comparative_analysis.md
```

---

## ğŸš€ Workflow de Experimentos

### **Fase 1: PreparaÃ§Ã£o de Dados**

```bash
# 1. Preparar dataset base (usa v6_dataset se jÃ¡ existe)
python3 pesquisa_v7/scripts/001_prepare_dataset.py \
  --base-path /home/chiarorosa/experimentos/uvg/ \
  --output-dir pesquisa_v7/v7_dataset

# 2. Preparar datasets Stage 3
python3 pesquisa_v7/scripts/002_prepare_stage3_datasets.py \
  --dataset-dir pesquisa_v7/v7_dataset/block_16
```

### **Fase 2: Baseline (ReproduÃ§Ã£o v6)**

```bash
# Treinar baseline para comparaÃ§Ã£o
python3 pesquisa_v7/scripts/010_baseline_v6_reproduction.py \
  --dataset-dir pesquisa_v7/v7_dataset/block_16 \
  --output-dir pesquisa_v7/logs/v7_experiments/baseline
```

### **Fase 3: SoluÃ§Ã£o 1 - Conv-Adapter**

```bash
# Treinar com Conv-Adapter
python3 pesquisa_v7/scripts/020_train_adapter_solution.py \
  --dataset-dir pesquisa_v7/v7_dataset/block_16 \
  --stage1-checkpoint <path_to_stage1> \
  --adapter-reduction 4 \
  --output-dir pesquisa_v7/logs/v7_experiments/solution1_adapter
```

### **Fase 4: SoluÃ§Ã£o 2 - Ensemble**

```bash
# Treinar ensemble (3 modelos)
python3 pesquisa_v7/scripts/030_train_ensemble_solution.py \
  --dataset-dir pesquisa_v7/v7_dataset/block_16 \
  --num-models 3 \
  --output-dir pesquisa_v7/logs/v7_experiments/solution2_ensemble
```

### **Fase 5: SoluÃ§Ã£o 3 - HÃ­brido** â­

```bash
# Treinar soluÃ§Ã£o hÃ­brida (RECOMENDADO)
python3 pesquisa_v7/scripts/040_train_hybrid_solution.py \
  --dataset-dir pesquisa_v7/v7_dataset/block_16 \
  --stage1-checkpoint <path_to_stage1> \
  --num-adapters 3 \
  --output-dir pesquisa_v7/logs/v7_experiments/solution3_hybrid
```

### **Fase 6: AvaliaÃ§Ã£o Comparativa**

```bash
# Comparar todas as soluÃ§Ãµes
python3 pesquisa_v7/scripts/050_evaluate_all_solutions.py \
  --baseline-dir pesquisa_v7/logs/v7_experiments/baseline \
  --adapter-dir pesquisa_v7/logs/v7_experiments/solution1_adapter \
  --ensemble-dir pesquisa_v7/logs/v7_experiments/solution2_ensemble \
  --hybrid-dir pesquisa_v7/logs/v7_experiments/solution3_hybrid \
  --output-file pesquisa_v7/logs/v7_experiments/comparative_results.json
```

---

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### **MÃ©tricas Principais:**
1. **F1-score macro** (por stage e pipeline completo)
2. **F1 per-class** (especialmente classes raras: HORZ_A/B, VERT_A/B, HORZ_4, VERT_4)
3. **Accuracy**
4. **Precision/Recall**

### **MÃ©tricas SecundÃ¡rias:**
5. **Parameter efficiency** (% parÃ¢metros treinÃ¡veis)
6. **Training time** (epochs to convergence)
7. **Inference speed** (samples/second)
8. **Confusion matrix** (anÃ¡lise de erros)

### **ComparaÃ§Ã£o Esperada:**

| SoluÃ§Ã£o | Stage 2 F1 | Stage 3-AB F1 | Pipeline F1 | Trainable Params |
|---------|------------|---------------|-------------|------------------|
| Baseline v6 | 46% | 24.5% | ~65% | 100% |
| Conv-Adapter | **60-65%** | **40-45%** | **~68-72%** | **3.5%** |
| Ensemble | 50-55% | 30-35% | ~70% | 300% |
| **Hybrid** | **65-73%** | **45-50%** | **70-75%** | **~10%** |

---

## ğŸ”¬ Protocolo Experimental (PhD-Level)

### **HipÃ³teses CientÃ­ficas:**

**H1 (Conv-Adapter):** Congelar backbone apÃ³s Stage 1 e usar adapters elimina negative transfer, aumentando F1 do Stage 2 de 46% para >60%.

**H2 (Ensemble):** Diversidade arquitetural compensa erros individuais, aumentando F1 pipeline em 5-8% absoluto.

**H3 (HÃ­brido):** CombinaÃ§Ã£o de adapters (efficiency) + ensemble (robustness) supera ambas soluÃ§Ãµes isoladas.

### **ValidaÃ§Ã£o:**

1. **Ablation Studies:**
   - Adapter vs Full fine-tuning vs Frozen backbone
   - Reduction ratio (Î³=2, 4, 8, 16)
   - NÃºmero de adapters no ensemble (2, 3, 5)
   - Soft voting vs Hard voting

2. **Controles:**
   - Mesmo dataset split (train/val)
   - Mesmos hiperparÃ¢metros base (lr, batch_size)
   - Mesmo seed (42) para reprodutibilidade
   - GPU fixa (mesmo hardware)

3. **AnÃ¡lise EstatÃ­stica:**
   - 3 runs por experimento (mÃ©dia Â± std)
   - Teste de significÃ¢ncia (>5% melhoria = significativo)
   - Intervalos de confianÃ§a 95%

### **Artifacts:**

Para cada experimento, salvar:
- âœ… Checkpoints (best e final)
- âœ… Training history (losses, metrics por epoch)
- âœ… Confusion matrix
- âœ… Per-class metrics
- âœ… Attention maps (adapters)
- âœ… Ensemble weights (learned)

---

## ğŸ“– DocumentaÃ§Ã£o para Tese

Cada soluÃ§Ã£o terÃ¡ documentaÃ§Ã£o completa em `docs_v7/`:

### **Estrutura de cada documento:**

1. **MotivaÃ§Ã£o** (2-3 parÃ¡grafos)
2. **Literatura Foundation** (5-10 papers citados)
3. **HipÃ³tese** (testÃ¡vel, quantitativa)
4. **Protocolo Experimental** (reprodutÃ­vel)
5. **Arquitetura Detalhada** (diagramas, equaÃ§Ãµes)
6. **Resultados** (tabelas, grÃ¡ficos, confusion matrices)
7. **AnÃ¡lise CrÃ­tica** (por que funcionou/falhou?)
8. **Limitations** (o que nÃ£o foi testado?)
9. **ContribuiÃ§Ãµes** (inovaÃ§Ã£o PhD-level)
10. **References** (bibliografia completa)

---

## ğŸ“ ContribuiÃ§Ãµes AcadÃªmicas

### **InovaÃ§Ãµes deste trabalho:**

1. **Primeira aplicaÃ§Ã£o de Conv-Adapter** (Chen et al., CVPR 2024) em **prediÃ§Ã£o de partiÃ§Ãµes de codecs de vÃ­deo**
   - DomÃ­nio: Computer Vision â†’ Video Compression
   - Desafio: Negative transfer em classificaÃ§Ã£o hierÃ¡rquica

2. **Ensemble hierÃ¡rquico multi-stage** para classificaÃ§Ã£o desbalanceada
   - NÃ£o apenas ensemble no final (comum)
   - Voting em CADA estÃ¡gio da hierarquia

3. **HÃ­brido Adapter+Ensemble** para efficiency + robustness
   - CombinaÃ§Ã£o inÃ©dita na literatura
   - Trade-off otimizado: 10% params, 70-75% F1

4. **Benchmark completo** para AV1 partition prediction
   - Dataset pÃºblico (UVG)
   - 3 soluÃ§Ãµes comparadas rigorosamente
   - CÃ³digo reprodutÃ­vel

### **PossÃ­veis publicaÃ§Ãµes:**

1. **Workshop paper** (CVPR/ICCV): "Conv-Adapter for Video Codec Partition Prediction"
2. **Journal paper** (IEEE TIP/TCSVT): "Hierarchical Ensemble Methods for AV1 Encoding Acceleration"
3. **Thesis chapter**: "Parameter-Efficient Transfer Learning for Fine-Grained Video Classification"

---

## âš™ï¸ Requisitos

### **Ambiente:**
- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (GPU obrigatÃ³ria)
- 16GB+ RAM
- ~50GB storage (datasets + checkpoints)

### **DependÃªncias:**
Mesmas do v6 (ver `/requirements.txt`)

---

## ğŸ“ TODO

### **Prioridade Alta:**
- [ ] Criar scripts 010-050 (treinamento e avaliaÃ§Ã£o)
- [ ] Treinar Stage 1 baseline (necessÃ¡rio para todas soluÃ§Ãµes)
- [ ] Implementar Solution 1 (Conv-Adapter)
- [ ] Validar adapter com ablation (reduction=4,8,16)

### **Prioridade MÃ©dia:**
- [ ] Implementar Solution 2 (Ensemble)
- [ ] Testar diversidade: ResNet18 vs MobileNetV2
- [ ] Implementar Solution 3 (Hybrid)
- [ ] Grid search: num_adapters (2,3,5)

### **Prioridade Baixa:**
- [ ] Criar ARCHITECTURE_V7.md com diagramas
- [ ] Documentar experiments em docs_v7/
- [ ] Gerar visualizaÃ§Ãµes (attention maps, confusion matrices)
- [ ] Preparar material para tese

---

## ğŸ”— ReferÃªncias RÃ¡pidas

- **v6 (versÃ£o anterior):** `/pesquisa_v6/`
- **Dataset raw:** `/home/chiarorosa/experimentos/uvg/`
- **Artigos base:** `/pesquisa_v6/artigos/`
- **Copilot instructions:** `/.github/copilot-instructions.md`

---

## ğŸ‘¤ Autor

**Chiaro Rosa**  
PhD Candidate  
Research: Deep Learning for AV1 Video Codec Optimization

**Contact:** chiarorosa@...  
**Repository:** https://github.com/chiarorosa/cnn-av1-research

---

## ğŸ“„ LicenÃ§a

CÃ³digo acadÃªmico para pesquisa de doutorado.  
Para uso comercial, entrar em contato.

---

**Ãšltima atualizaÃ§Ã£o:** 14 de Outubro de 2025  
**Status:** ğŸš§ Em desenvolvimento ativo
