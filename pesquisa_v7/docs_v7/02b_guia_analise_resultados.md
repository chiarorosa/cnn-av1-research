# Guia de An√°lise de Resultados - Experimento Adapter Capacity

**Experimento:** Aumento de capacidade do adapter (Œ≥=4 ‚Üí Œ≥=2)  
**Script:** 020_train_adapter_solution.py  
**Output:** pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/

---

## 1. Verificar Conclus√£o do Treinamento

### Comando para verificar status:
```bash
cd /home/chiarorosa/CNN_AV1
ls -lh pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/stage2_adapter/
```

**Arquivos esperados**:
- ‚úÖ `stage2_adapter_model_best.pt` - Melhor checkpoint
- ‚úÖ `stage2_adapter_history.pt` - Hist√≥rico de treino
- ‚úÖ `stage2_adapter_metrics.json` - M√©tricas finais
- ‚úÖ `stage2_adapter_model_final.pt` - Checkpoint final (opcional)

**Se arquivos n√£o existirem**: Treinamento ainda em andamento. Aguarde.

---

## 2. Extrair M√©tricas Principais

### Comando para ler m√©tricas:
```bash
cd /home/chiarorosa/CNN_AV1
python3 -c "
import json
with open('pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/stage2_adapter/stage2_adapter_metrics.json', 'r') as f:
    m = json.load(f)
    
print('=== STAGE 2 - ADAPTER REDUCTION=2 ===')
print(f'Val F1: {m[\"val_f1\"]*100:.2f}%')
print(f'Train F1: {m[\"train_f1\"]*100:.2f}%')
print(f'Train-Val Gap: {(m[\"train_f1\"] - m[\"val_f1\"])*100:.2f}%')
print(f'Best epoch: {m[\"best_epoch\"]}')
print(f'Total epochs: {m[\"total_epochs\"]}')
print()
print('Per-class (validation):')
for cls, metrics in m['val_per_class'].items():
    print(f'  {cls}: F1={metrics[\"f1\"]:.4f}, P={metrics[\"precision\"]:.4f}, R={metrics[\"recall\"]:.4f}')
"
```

### Compara√ß√£o com Baseline (Œ≥=4):
```bash
cd /home/chiarorosa/CNN_AV1
python3 -c "
import json

# Baseline (Œ≥=4)
with open('pesquisa_v7/logs/v7_experiments/solution1_adapter/stage2_adapter/stage2_adapter_metrics.json', 'r') as f:
    m4 = json.load(f)

# Novo (Œ≥=2)
with open('pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/stage2_adapter/stage2_adapter_metrics.json', 'r') as f:
    m2 = json.load(f)

print('=== COMPARISON: Œ≥=4 vs Œ≥=2 ===')
print(f'Baseline (Œ≥=4): Val F1 = {m4[\"val_f1\"]*100:.2f}%')
print(f'Experiment (Œ≥=2): Val F1 = {m2[\"val_f1\"]*100:.2f}%')
print(f'Delta: {(m2[\"val_f1\"] - m4[\"val_f1\"])*100:.2f} percentage points')
print()
print(f'Baseline gap: {(m4[\"train_f1\"] - m4[\"val_f1\"])*100:.2f}%')
print(f'Experiment gap: {(m2[\"train_f1\"] - m2[\"val_f1\"])*100:.2f}%')
print()
print(f'Baseline epochs: {m4[\"total_epochs\"]} (best at {m4[\"best_epoch\"]})')
print(f'Experiment epochs: {m2[\"total_epochs\"]} (best at {m2[\"best_epoch\"]})')
"
```

---

## 3. An√°lise Visual das Curvas

### Plotar curvas de aprendizado:
```bash
cd /home/chiarorosa/CNN_AV1
python3 << 'EOF'
import torch
import matplotlib.pyplot as plt
import numpy as np

# Carregar histories
hist_g4 = torch.load('pesquisa_v7/logs/v7_experiments/solution1_adapter/stage2_adapter/stage2_adapter_history.pt', weights_only=False)
hist_g2 = torch.load('pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/stage2_adapter/stage2_adapter_history.pt', weights_only=False)

# Criar figura
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. Loss curves
axes[0, 0].plot(hist_g4['train_loss'], label='Train (Œ≥=4)', linestyle='--', alpha=0.7)
axes[0, 0].plot(hist_g4['val_loss'], label='Val (Œ≥=4)', linestyle='--', linewidth=2)
axes[0, 0].plot(hist_g2['train_loss'], label='Train (Œ≥=2)', linestyle='-', alpha=0.7)
axes[0, 0].plot(hist_g2['val_loss'], label='Val (Œ≥=2)', linestyle='-', linewidth=2)
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)
axes[0, 0].set_title('Loss Curves: Adapter Capacity Comparison')

# 2. F1 curves
axes[0, 1].plot(hist_g4['train_f1'], label='Train (Œ≥=4)', linestyle='--', alpha=0.7)
axes[0, 1].plot(hist_g4['val_f1'], label='Val (Œ≥=4)', linestyle='--', linewidth=2)
axes[0, 1].plot(hist_g2['train_f1'], label='Train (Œ≥=2)', linestyle='-', alpha=0.7)
axes[0, 1].plot(hist_g2['val_f1'], label='Val (Œ≥=2)', linestyle='-', linewidth=2)
axes[0, 1].axhline(y=0.60, color='green', linestyle=':', label='Target (60%)', alpha=0.5)
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('F1-score')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)
axes[0, 1].set_title('F1 Curves: Adapter Capacity Comparison')

# 3. Train-Val Gap
gap_g4 = np.array(hist_g4['train_f1']) - np.array(hist_g4['val_f1'])
gap_g2 = np.array(hist_g2['train_f1']) - np.array(hist_g2['val_f1'])
axes[1, 0].plot(gap_g4, label='Œ≥=4 (166k params)', linestyle='--', linewidth=2)
axes[1, 0].plot(gap_g2, label='Œ≥=2 (332k params)', linestyle='-', linewidth=2)
axes[1, 0].axhline(y=0.05, color='green', linestyle=':', label='Healthy (5%)', alpha=0.5)
axes[1, 0].axhline(y=0.08, color='orange', linestyle=':', label='Warning (8%)', alpha=0.5)
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Train - Val F1')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)
axes[1, 0].set_title('Generalization Gap')

# 4. Learning Rate Schedule
axes[1, 1].plot(hist_g4['learning_rates'], label='Œ≥=4', linestyle='--', linewidth=2)
axes[1, 1].plot(hist_g2['learning_rates'], label='Œ≥=2', linestyle='-', linewidth=2)
axes[1, 1].set_xlabel('Epoch')
axes[1, 1].set_ylabel('Learning Rate')
axes[1, 1].set_yscale('log')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)
axes[1, 1].set_title('Learning Rate Schedule')

plt.tight_layout()
plt.savefig('pesquisa_v7/docs_v7/figures/adapter_capacity_comparison.png', dpi=150, bbox_inches='tight')
print('‚úÖ Figura salva em: pesquisa_v7/docs_v7/figures/adapter_capacity_comparison.png')
plt.close()

# Figura adicional: Per-class F1 comparison
import json
with open('pesquisa_v7/logs/v7_experiments/solution1_adapter/stage2_adapter/stage2_adapter_metrics.json', 'r') as f:
    m4 = json.load(f)
with open('pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/stage2_adapter/stage2_adapter_metrics.json', 'r') as f:
    m2 = json.load(f)

classes = list(m4['val_per_class'].keys())
f1_g4 = [m4['val_per_class'][c]['f1'] for c in classes]
f1_g2 = [m2['val_per_class'][c]['f1'] for c in classes]

x = np.arange(len(classes))
width = 0.35

fig, ax = plt.subplots(figsize=(10, 6))
bars1 = ax.bar(x - width/2, f1_g4, width, label='Œ≥=4', alpha=0.8)
bars2 = ax.bar(x + width/2, f1_g2, width, label='Œ≥=2', alpha=0.8)

ax.set_xlabel('Class')
ax.set_ylabel('F1-score')
ax.set_title('Per-Class F1: Adapter Capacity Comparison')
ax.set_xticks(x)
ax.set_xticklabels(classes, rotation=15, ha='right')
ax.legend()
ax.grid(True, alpha=0.3, axis='y')

# Adicionar valores nas barras
for bar in bars1:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.3f}', ha='center', va='bottom', fontsize=9)
for bar in bars2:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.3f}', ha='center', va='bottom', fontsize=9)

plt.tight_layout()
plt.savefig('pesquisa_v7/docs_v7/figures/adapter_capacity_per_class.png', dpi=150, bbox_inches='tight')
print('‚úÖ Figura salva em: pesquisa_v7/docs_v7/figures/adapter_capacity_per_class.png')
EOF
```

**Nota:** Crie o diret√≥rio de figuras primeiro:
```bash
mkdir -p pesquisa_v7/docs_v7/figures
```

---

## 4. Inspe√ß√£o do Checkpoint

### Verificar par√¢metros do adapter:
```bash
cd /home/chiarorosa/CNN_AV1
python3 << 'EOF'
import torch

ckpt = torch.load('pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/stage2_adapter/stage2_adapter_model_best.pt', weights_only=False)

# Encontrar par√¢metros do adapter
model_keys = list(ckpt['model_state_dict'].keys())
adapter_keys = [k for k in model_keys if any(x in k for x in ['down_proj', 'up_proj', 'alpha', 'dw_conv'])]

print('=== ADAPTER ARCHITECTURE (Œ≥=2) ===')
print(f'Total model keys: {len(model_keys)}')
print(f'Adapter-specific keys: {len(adapter_keys)}')
print()

# Contar par√¢metros por layer
layer3_params = sum(ckpt['model_state_dict'][k].numel() for k in adapter_keys if 'layer3' in k)
layer4_params = sum(ckpt['model_state_dict'][k].numel() for k in adapter_keys if 'layer4' in k)

print(f'Layer 3 adapter params: {layer3_params:,}')
print(f'Layer 4 adapter params: {layer4_params:,}')
print(f'Total adapter params: {layer3_params + layer4_params:,}')
print()

# Mostrar shapes
print('=== PARAMETER SHAPES ===')
for k in sorted(adapter_keys):
    shape = ckpt['model_state_dict'][k].shape
    params = ckpt['model_state_dict'][k].numel()
    print(f'{k}: {shape} ({params:,} params)')

print()
print(f'Parameter efficiency: {ckpt["param_efficiency"]:.2f}%')
print(f'Best epoch: {ckpt["best_epoch"]}')
print(f'Val F1 at best: {ckpt["val_f1_at_best"]:.4f}')
EOF
```

---

## 5. Decis√£o: Adotar ou N√£o?

### Crit√©rios de Decis√£o:

**‚úÖ ADOTAR Œ≥=2 se:**
1. ŒîF1 ‚â• 2% (ganho significativo, Chen et al. prediction)
2. Train-val gap 5-8% (saud√°vel, sem overfitting)
3. Converg√™ncia est√°vel (sem diverg√™ncia)
4. Pelo menos 1 classe melhorou substancialmente

**‚ö†Ô∏è CONSIDERAR se:**
1. ŒîF1 entre 1-2% (ganho marginal)
2. Train-val gap < 10% (ainda controlado)
3. Converg√™ncia mais lenta mas est√°vel
4. Trade-off F1 vs params √© aceit√°vel (0.5-1.0 F1 points per 100k params)

**‚ùå REJEITAR Œ≥=2 se:**
1. ŒîF1 < 1% (sem ganho pr√°tico)
2. Train-val gap > 10% (overfitting severo)
3. Instabilidade no treino (loss oscilante)
4. Todas as classes pioraram ou mantiveram

### Comando para decis√£o automatizada:
```bash
cd /home/chiarorosa/CNN_AV1
python3 << 'EOF'
import json

# Carregar m√©tricas
with open('pesquisa_v7/logs/v7_experiments/solution1_adapter/stage2_adapter/stage2_adapter_metrics.json', 'r') as f:
    m4 = json.load(f)
with open('pesquisa_v7/logs/v7_experiments/solution1_adapter_reduction2/stage2_adapter/stage2_adapter_metrics.json', 'r') as f:
    m2 = json.load(f)

# Calcular m√©tricas de decis√£o
delta_f1 = (m2['val_f1'] - m4['val_f1']) * 100
gap_g2 = (m2['train_f1'] - m2['val_f1']) * 100

print('=== DECISION CRITERIA ===')
print(f'ŒîF1: {delta_f1:+.2f} percentage points')
print(f'Train-Val Gap (Œ≥=2): {gap_g2:.2f}%')
print()

# Decis√£o
if delta_f1 >= 2.0 and gap_g2 <= 8.0:
    print('‚úÖ RECOMENDA√á√ÉO: ADOTAR Œ≥=2')
    print('   Ganho significativo sem overfitting')
elif delta_f1 >= 1.0 and gap_g2 <= 10.0:
    print('‚ö†Ô∏è  RECOMENDA√á√ÉO: CONSIDERAR Œ≥=2')
    print('   Ganho marginal, avaliar trade-off')
else:
    print('‚ùå RECOMENDA√á√ÉO: MANTER Œ≥=4')
    print('   Ganho insuficiente ou overfitting')
EOF
```

---

## 6. Atualizar Documenta√ß√£o

### Ap√≥s decidir, atualizar:

**Arquivo:** `pesquisa_v7/docs_v7/02_experimento_adapter_capacity.md`

**Se√ß√£o 4 - Resultados**: Preencher tabela com valores reais

**Se√ß√£o 5 - An√°lise Comparativa**: Completar an√°lise com conclus√µes

**Se√ß√£o 6 - Curvas**: Adicionar figuras geradas

**Se√ß√£o 7 - Discuss√£o**: Escrever interpreta√ß√£o final

### Se ADOTAR Œ≥=2:

**Arquivo:** `pesquisa_v7/scripts/020_train_adapter_solution.py`
- ‚úÖ J√° atualizado com `default=2`

**Arquivo:** `pesquisa_v7/README.md`
- Adicionar nota sobre Œ≥=2 como configura√ß√£o recomendada

**Arquivo:** `pesquisa_v7/ARQUITETURA_V7.md`
- Atualizar diagrama com Œ≥=2

### Se MANTER Œ≥=4:

**Arquivo:** `pesquisa_v7/scripts/020_train_adapter_solution.py`
- Reverter para `default=4`
- Documentar Œ≥=2 como tentativa n√£o bem-sucedida

---

## 7. Pr√≥ximos Experimentos

### Se Œ≥=2 foi bem-sucedido:
1. Aplicar Œ≥=2 em Stage 3 (RECT e AB specialists)
2. Testar ensemble com Œ≥=2
3. Documentar como best practice

### Se Œ≥=2 falhou:
1. Investigar outras causas do underfitting:
   - BatchNorm distribution shift
   - Loss function inadequada
   - Features do Stage 1 n√£o √≥timas
2. Testar outras solu√ß√µes:
   - Solution 2 (Ensemble)
   - Solution 3 (Hybrid)
   - Knowledge Distillation

---

## 8. Checklist de An√°lise Completa

- [ ] Verificar que treinamento terminou (arquivos .pt e .json existem)
- [ ] Extrair m√©tricas principais (F1, gap, epochs)
- [ ] Comparar com baseline Œ≥=4
- [ ] Gerar figuras de curvas de aprendizado
- [ ] Inspecionar checkpoint e confirmar par√¢metros
- [ ] Aplicar crit√©rios de decis√£o
- [ ] Atualizar documento 02_experimento_adapter_capacity.md
- [ ] Tomar decis√£o: adotar, considerar, ou rejeitar
- [ ] Atualizar scripts e documenta√ß√£o conforme decis√£o
- [ ] Planejar pr√≥ximos experimentos
- [ ] Integrar resultados com tese (Cap√≠tulos 4, 5, 6)

---

**√öltima atualiza√ß√£o**: 16/10/2025  
**Status**: üìã Guia de an√°lise pronto  
**Pr√≥ximo passo**: Aguardar conclus√£o do treinamento e executar comandos deste guia
