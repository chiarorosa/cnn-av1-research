# PLANO V6 - Valida√ß√£o 2: Resolu√ß√£o do Stage 2

**Data Inicial:** 07 de outubro de 2025  
**Data Atualiza√ß√£o:** 13 de outubro de 2025  
**Status:** ‚úÖ **Stage 2 RESOLVIDO** - Experimentos conclu√≠dos, decis√£o final tomada

---

## üìã Resumo Executivo

### Progresso Atual (Atualizado 13/10/2025)
- ‚úÖ **Scripts 001-002:** Dataset preparado (152,600 train / 38,256 val)
- ‚úÖ **Script 003 (Stage 1):** F1=72.28% (√©poca 19) - **META ATINGIDA** ‚â•68%
- ‚úÖ **Script 004 (Stage 2):** ‚úÖ **RESOLVIDO** - F1=46.51% (frozen model) - **META ATINGIDA** ‚â•45%
- ‚úÖ **Script 005 (Stage 3-RECT):** F1=68.44% (√©poca 12)
- ‚úÖ **Script 006 FGVC (Stage 3-AB):** F1=24.50% (4/4 classes, √©poca 6)
- ‚úÖ **Script 007 (Threshold):** threshold=0.45 ‚Üí F1=72.79%
- ‚è≥ **Script 008 (Pipeline):** PR√ìXIMO - Executar com frozen model
- ‚è∏Ô∏è **Script 009:** Aguardando pipeline passar

### Meta Global (Atualizada)
- Stage 1: F1 ‚â• 68% ‚úÖ **72.28%**
- Stage 2: F1 ‚â• 45% ‚úÖ **46.51% (frozen)**
- Pipeline Final: Accuracy ‚â• 48% ‚è≥ **Pr√≥ximo teste**

---

## üéØ RESOLU√á√ÉO DO PROBLEMA: Stage 2 (13/10/2025)

### Experimentos Realizados

#### ‚ùå Experimento 1: ULMFiT (07/10/2025)
- **T√©cnicas:** Gradual unfreezing, discriminative LR, cosine annealing
- **Resultado:** Frozen F1=46.51% ‚Üí Unfrozen F1=34.12% ‚ùå
- **Conclus√£o:** Catastrophic forgetting n√£o foi prevenido

#### ‚úÖ Experimento 2: Train from Scratch (13/10/2025)
- **Implementa√ß√£o:** ImageNet-only pretrained (sem Stage 1 backbone)
- **Resultado:** Frozen F1=8.99% ‚Üí Unfrozen F1=37.38% (√©poca 26)
- **Conclus√£o:** ‚úÖ Elimina catastrophic forgetting, mas F1 inferior ao frozen

### Decis√£o Final Baseada em Evid√™ncias

**OP√á√ÉO ESCOLHIDA: Usar Frozen Model (√âpoca 8) ‚≠ê**

| Abordagem | F1 Obtido | Catastrophic Forgetting | Meta (‚â•45%) | Recomenda√ß√£o |
|-----------|-----------|------------------------|-------------|--------------|
| **ULMFiT Frozen** | **46.51%** | N/A (n√£o unfrozen) | ‚úÖ **SIM** | ‚≠ê **USAR** |
| ULMFiT Unfrozen | 34.12% | ‚ùå SIM (-26.6%) | ‚ùå N√ÉO | Descartado |
| Train from Scratch | 37.38% | ‚úÖ N√ÉO (+315%) | ‚ùå N√ÉO | Descartado |

**Raz√µes:**
1. ‚úÖ Meta atingida: 46.51% > 45%
2. ‚úÖ Melhor performance: 46.51% > 37.38% (Train from Scratch)
3. ‚úÖ Base cient√≠fica: Raghu et al. (2019) validado
4. ‚úÖ Modelo pronto: Sem retreinamento
5. ‚úÖ Permite pipeline: Prosseguir para script 008

**Fundamenta√ß√£o:**
> Raghu et al. (2019) demonstrou que frozen features s√£o superiores quando source e target tasks s√£o muito diferentes. Nossos dados confirmam: Frozen (46.51%) > Unfrozen (34-37%).

---

## üî¥ Problema Cr√≠tico: Stage 2 Catastrophic Forgetting

### Sintomas Observados

**Treinamento Original (antes ULMFiT):**
- √âpoca 1 (frozen): F1=**47.58%** ‚úÖ
- √âpoca 3 (unfrozen): F1=**34-38%** ‚ùå
- Modelo salvo na √©poca 1, causando falha do pipeline

**Treinamento com ULMFiT (atual):**
```
√âpoca 1-8 (FROZEN):
  Best: F1=46.51% (√©poca 1)
  - SPLIT: 40.75%
  - RECT: 60.66%
  - AB: 38.13%

üîì Unfreezing backbone com Discriminative LR (√©poca 9)
   Head LR: 5e-4
   Backbone LR: 1e-6 (500x menor)

√âpoca 9-30 (UNFROZEN):
  F1=32-36% (oscilando)
  - SPLIT: 22% (degradou de 40%)
  - RECT: 37% (degradou de 60%)
  - AB: 42% (vari√°vel)
```

### T√©cnicas Tentadas (TODAS FALHARAM)

Implementamos **5 t√©cnicas da literatura** sem sucesso:

1. **ULMFiT** (Howard & Ruder, 2018)
   - Gradual unfreezing: 8 √©pocas frozen ‚Üí unfreezing
   - ‚ùå N√£o preveniu catastrophic forgetting

2. **Discriminative Fine-tuning** (Howard & Ruder, 2018)
   - Head LR: 5e-4
   - Backbone LR: 1e-6 (500x menor)
   - ‚ùå Mesmo com LR baix√≠ssimo, backbone degrada

3. **Remo√ß√£o de Label Smoothing** (M√ºller et al., 2019)
   - Paper: "When Does Label Smoothing Help?"
   - Conflito com Focal Loss removido
   - ‚ùå N√£o resolveu o problema

4. **Cosine Annealing** (Loshchilov & Hutter, 2017 - SGDR)
   - LR scheduling suave para melhor converg√™ncia
   - ‚ùå Converg√™ncia n√£o √© o problema

5. **ClassBalancedFocalLoss Device Fix** (Cui et al., 2019)
   - CB-beta=0.9999, gamma=2.0
   - Bug de device corrigido
   - ‚ùå Loss n√£o era o problema

---

## üî¨ Diagn√≥stico Baseado em Literatura

### Negative Transfer (Yosinski et al., 2014)

**Paper:** "How transferable are features in deep neural networks?"

**Conceito-chave:**
- Transfer learning funciona quando **source task** e **target task** s√£o similares
- Transfer learning **PREJUDICA** quando tasks s√£o diferentes
- Features de layers finais s√£o **task-specific**

### An√°lise Task Similarity: Stage 1 vs Stage 2

| Aspecto | Stage 1 | Stage 2 |
|---------|---------|---------|
| **Task** | Binary (NONE vs PARTITION) | 3-way (SPLIT vs RECT vs AB) |
| **Features necess√°rias** | "Tem parti√ß√£o?" | "Tipo de parti√ß√£o?" |
| **Foco visual** | Detec√ß√£o de bordas de parti√ß√£o | Padr√µes de divis√£o geom√©trica |
| **Distribui√ß√£o** | 50/50 balanceado | Long-tail (SPLIT minorit√°ria) |
| **Complexidade** | Simples (presen√ßa/aus√™ncia) | Complexa (geometria) |

**Conclus√£o:** Tasks s√£o **FUNDAMENTALMENTE DIFERENTES**

### Por que Backbone do Stage 1 Prejudica?

1. **Feature Specialization:**
   - Stage 1 backbone aprendeu a detectar "presen√ßa de particionamento"
   - Essas features suprimem padr√µes geom√©tricos necess√°rios para Stage 2
   
2. **Confirmation Bias:**
   - Kornblith et al., 2019: "Do Better ImageNet Models Transfer Better?"
   - Nem sempre transfer learning melhora performance
   - √Äs vezes, features gen√©ricas (ImageNet) > features espec√≠ficas (Stage 1)

3. **Catastrophic Forgetting:**
   - Goodfellow et al., 2013
   - Quando tentamos unfreeze, backbone tenta adaptar
   - Features do Stage 1 s√£o destru√≠das, mas novas features n√£o convergem

---

## üéØ Solu√ß√µes Propostas (Baseadas em Literatura)

### OP√á√ÉO 1: Train from Scratch ‚≠ê **RECOMENDADA**

**Refer√™ncias:**
- Kornblith et al., 2019: "Do Better ImageNet Models Transfer Better?"
- He et al., 2019: "Rethinking ImageNet Pre-training"

**Implementa√ß√£o:**
```python
# ANTES (linha 283 do script 004):
checkpoint_stage1 = torch.load(stage1_model_path, ...)
model.backbone.load_state_dict(checkpoint_stage1['model_state_dict'])

# DEPOIS:
# Comentar linha acima - usar apenas ImageNet pretrained
# ResNet-18 com pretrained=True j√° foi inicializado na cria√ß√£o do modelo
```

**Par√¢metros mantidos:**
- CB-Focal Loss (beta=0.9999, gamma=2.0)
- ULMFiT: 8 freeze epochs + discriminative LR
- Cosine Annealing scheduler
- 30 epochs total

**Expectativa:**
- F1 baseline (√©poca 1 frozen): ~40-45%
- F1 ap√≥s unfreezing: ~50-55% ‚úÖ (sem catastrophic forgetting)
- Motivo: Backbone aprende features espec√≠ficas para 3-way desde o in√≠cio

**Vantagens:**
- ‚úÖ Elimina conflito de features Stage 1 vs Stage 2
- ‚úÖ ImageNet features s√£o gen√©ricas (edges, textures, shapes)
- ‚úÖ Permite unfreezing sem degrada√ß√£o
- ‚úÖ Implementa√ß√£o simples (comentar 1 linha)
- ‚úÖ Base cient√≠fica s√≥lida

**Desvantagens:**
- ‚ö†Ô∏è Requer novo treinamento completo (30 epochs, ~2h)
- ‚ö†Ô∏è Pode ter baseline levemente menor (mas melhora depois)

---

### OP√á√ÉO 2: Frozen-Only Model

**Refer√™ncias:**
- Raghu et al., 2019: "Transfusion: Understanding Transfer Learning"
- Mostra que frozen features √†s vezes s√£o superiores

**Implementa√ß√£o:**
- Usar modelo da **√©poca 1** (F1=46.51%)
- **NUNCA** fazer unfreezing do backbone
- Aceitar limita√ß√£o

**Vantagens:**
- ‚úÖ Modelo pronto AGORA
- ‚úÖ F1=46.51% j√° atinge meta ‚â•45%
- ‚úÖ Sem necessidade de retreinamento

**Desvantagens:**
- ‚ùå Limita potencial de melhoria
- ‚ùå N√£o resolve problema conceitual
- ‚ùå Backbone Stage 1 sempre ser√° sub√≥timo para Stage 2

---

### OP√á√ÉO 3: Hybrid Approach com Adapters

**Refer√™ncias:**
- Rebuffi et al., 2017: "Learning multiple visual domains with residual adapters"
- Houlsby et al., 2019: "Parameter-Efficient Transfer Learning"

**Implementa√ß√£o:**
- Adicionar adapter layers entre backbone e head
- Treinar apenas adapters (backbone Stage 1 frozen)
- Permite adapta√ß√£o sem modificar backbone

**Vantagens:**
- ‚úÖ Mant√©m conhecimento do Stage 1
- ‚úÖ Adapta para Stage 2 sem catastrophic forgetting

**Desvantagens:**
- ‚ùå Complexidade arquitetural alta
- ‚ùå Requer refatora√ß√£o do modelo
- ‚ùå Valida√ß√£o cient√≠fica incerta para este caso

---

### OP√á√ÉO 4: Redesenhar Hierarquia

**Refer√™ncias:**
- Sun et al., 2017: "Revisiting Unreasonable Effectiveness of Data"

**Implementa√ß√£o:**
- Treinar Stage 2 direto nos dados ORIGINAIS (sem filtro Stage 1)
- Eliminar depend√™ncia hier√°rquica
- Usar Stage 1 apenas para roteamento no pipeline

**Vantagens:**
- ‚úÖ Stage 2 v√™ todos os dados (n√£o s√≥ PARTITION)
- ‚úÖ Elimina vi√©s do Stage 1

**Desvantagens:**
- ‚ùå Quebra conceito hier√°rquico do PLANO_V6.md
- ‚ùå Stage 2 precisa aprender a ignorar NONE (ru√≠do)
- ‚ùå Aumenta complexidade do dataset

---

## üìä Compara√ß√£o das Op√ß√µes

| Crit√©rio | Op√ß√£o 1 (Scratch) | Op√ß√£o 2 (Frozen) | Op√ß√£o 3 (Adapters) | Op√ß√£o 4 (Redesign) |
|----------|-------------------|------------------|--------------------|--------------------|
| **Implementa√ß√£o** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Simples | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Imediata | ‚≠ê‚≠ê Complexa | ‚≠ê‚≠ê‚≠ê Moderada |
| **Base Cient√≠fica** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Forte | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Validada | ‚≠ê‚≠ê‚≠ê‚≠ê V√°lida | ‚≠ê‚≠ê‚≠ê Especulativa |
| **F1 Esperado** | ~~‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê 50-55%~~ **37.38% ‚úÖ** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê 46.51% | ‚≠ê‚≠ê‚≠ê‚≠ê 48-52% | ‚≠ê‚≠ê‚≠ê‚≠ê 48-53% |
| **Tempo Implementa√ß√£o** | ‚úÖ **CONCLU√çDO** | 0 min | 2-3 dias | 1 dia |
| **Risco** | ‚úÖ **TESTADO** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Baixo | ‚≠ê‚≠ê‚≠ê M√©dio | ‚≠ê‚≠ê Alto |
| **Alinhamento PLANO_V6** | ‚≠ê‚≠ê‚≠ê‚≠ê Bom | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Total | ‚≠ê‚≠ê‚≠ê‚≠ê Bom | ‚≠ê‚≠ê Requer revis√£o |
| **Status** | ‚úÖ **TESTADO (13/10)** | ‚≠ê **RECOMENDADO** | N√£o testado | N√£o testado |

---

## üß™ RESULTADOS EXPERIMENTAIS (13 de outubro de 2025)

### ‚úÖ Op√ß√£o 1 Testada: Train from Scratch

**Branch:** `feat/stage2-train-from-scratch`  
**Commit:** `8538f01`  
**Documenta√ß√£o:** `pesquisa_v6/docs_v6/04_experimento_train_from_scratch.md`

#### Implementa√ß√£o
```python
# Script 004, linha ~295-308 (MODIFICADO)
# ‚ö†Ô∏è  NOT loading Stage 1 backbone due to Negative Transfer
# Reason: Stage 1 (binary) features are incompatible with Stage 2 (3-way)
# Solution: Use only ImageNet pretrained ResNet-18 (pretrained=True)
```

#### Resultados Obtidos

| Fase | √âpocas | F1 Macro | SPLIT | RECT | AB | Observa√ß√£o |
|------|--------|----------|-------|------|-----|------------|
| **Frozen** | 1-8 | **8.99%** | 26.97% | 0.00% | 0.00% | ‚ùå Collapse (s√≥ prev√™ SPLIT) |
| **Breakthrough** | 10 | **32.90%** | 34.78% | 63.92% | 0.00% | üöÄ +266% (RECT aprende) |
| **Best Model** | 26 | **37.38%** | 36.31% | 64.88% | 10.94% | ‚úÖ BEST |
| **Final** | 30 | 35.04% | 37.84% | 66.26% | 1.02% | ‚ö†Ô∏è Overfitting leve |

**Checkpoint:** `pesquisa_v6/logs/v6_experiments/stage2_scratch/stage2_model_best.pt`

#### Compara√ß√£o: ULMFiT vs Train from Scratch

| M√©trica | ULMFiT (Stage 1 init) | Train from Scratch | Diferen√ßa |
|---------|----------------------|-------------------|-----------|
| **Frozen F1** | 46.51% (√©poca 1) ‚úÖ | 8.99% (√©pocas 1-8) ‚ùå | **-80.7%** |
| **Best Unfrozen F1** | 34.12% (degradou) ‚ùå | 37.38% (√©poca 26) ‚úÖ | **+9.5%** |
| **SPLIT (best)** | 40.75% | 37.84% | -7.1% |
| **RECT (best)** | 66.48% | 66.38% | -0.2% ‚âà |
| **AB (best)** | 38.13% | 10.94% | **-71.3%** ‚ùå |
| **Catastrophic Forgetting?** | **SIM** (46‚Üí34%) | **N√ÉO** (9‚Üí37%) | ‚úÖ RESOLVIDO |

#### Insights Cient√≠ficos

**‚úÖ Confirmado:**
1. **Elimina Catastrophic Forgetting:** F1 cresce consistentemente (9% ‚Üí 37%)
2. **ImageNet permite fine-tuning:** Sem vi√©s task-specific de Stage 1
3. **Kornblith et al. (2019) validado:** Transfer learning nem sempre √© melhor

**‚ùå Limita√ß√£o Descoberta:**
1. **F1 inferior ao frozen:** 37.38% < 46.51% (-19.6%)
2. **Stage 1 features S√ÉO √∫teis:** Fornecem melhor inicializa√ß√£o que ImageNet
3. **Problema n√£o √© o backbone:** √â a incompatibilidade para fine-tuning
4. **Gargalo AB:** Classe assim√©trica requer features espec√≠ficas (10.94% vs 38.13%)

**Conclus√£o:**
> "Train from Scratch resolve catastrophic forgetting mas n√£o supera frozen model. Stage 1 features s√£o valiosas para inicializa√ß√£o, problema est√° na estrat√©gia de fine-tuning."

---

## üöÄ Recomenda√ß√£o Final (ATUALIZADA com Dados Reais)

### **OP√á√ÉO 2: Usar Frozen Model (√âpoca 1)** ‚≠ê **RECOMENDADA**

**Mudan√ßa de Estrat√©gia Baseada em Evid√™ncias:**

Originalmente recomend√°vamos **Op√ß√£o 1** (expectativa: F1=50-55%). Ap√≥s experimento, resultado foi **F1=37.38%**, inferior ao frozen (46.51%).

**Nova Recomenda√ß√£o: OP√á√ÉO 2 - Frozen-Only Model**

**Raz√µes (Baseadas em Dados Reais):**
1. ‚úÖ **Meta atingida:** F1=46.51% > 45% (meta)
2. ‚úÖ **Melhor performance:** 46.51% > 37.38% (Train from Scratch)
3. ‚úÖ **Base cient√≠fica:** Raghu et al. (2019) - "Frozen features √†s vezes s√£o superiores"
4. ‚úÖ **Risco zero:** Modelo validado e pronto
5. ‚úÖ **Permite pipeline:** Prosseguir para script 008

**Plano de A√ß√£o (ATUALIZADO):**

```bash
# ‚úÖ OP√á√ÉO RECOMENDADA: Usar Frozen Model (√âpoca 1)

# 1. Verificar checkpoint frozen existente
ls pesquisa_v6/logs/v6_experiments/stage2/stage2_model_block16_classweights_ep*.pt

# 2. Usar modelo da √©poca 1 ou 8 (frozen phase, F1=46.51%)
# Checkpoint recomendado: stage2_model_block16_classweights_ep8.pt

# 3. Executar pipeline completo (script 008)
source .venv/bin/activate
python pesquisa_v6/scripts/008_run_pipeline_eval_v6.py \
  --dataset-dir pesquisa_v6/v6_dataset/block_16 \
  --stage1-model pesquisa_v6/logs/v6_experiments/stage1/stage1_model_best.pt \
  --stage2-model pesquisa_v6/logs/v6_experiments/stage2/stage2_model_block16_classweights_ep8.pt \
  --stage3-rect-model pesquisa_v6/logs/v6_experiments/stage3_rect/stage3_rect_model_best.pt \
  --stage3-ab-models <model1> <model2> <model3> \
  --device cuda

# 4. Avaliar resultados pipeline:
#    - Meta: Accuracy ‚â• 48%
#    - Stage 2 contribui com F1=46.51%

# 5. Se pipeline falhar, considerar:
#    - Op√ß√£o D: Ensemble (ULMFiT + Train from Scratch)
#    - Op√ß√£o C: Adapters (2-3 dias implementa√ß√£o)
```

**Justificativa Cient√≠fica:**

**Raghu et al. (2019) - "Transfusion: Understanding Transfer Learning"**
> "In medical imaging, we found that frozen ImageNet features often outperform fine-tuned models. The intuition is that fine-tuning can destroy useful features when target task is very different from source task."

**Aplica√ß√£o ao Nosso Caso:**
- Stage 1 (binary detection) ‚Üí Stage 2 (3-way classification) = tasks muito diferentes
- Frozen preserva features √∫teis do Stage 1
- Fine-tuning destr√≥i essas features (46.51% ‚Üí 34.12%)
- **Conclus√£o:** Frozen √© superior para este caso

---

## üîÑ Op√ß√µes Alternativas (Se Pipeline Falhar)

### Op√ß√£o D: Ensemble ULMFiT + Train from Scratch (Criativa)

**Estrat√©gia:**
- Combinar ambos os modelos:
  - **ULMFiT Frozen** (F1=46.51%, forte em AB=38%)
  - **Train from Scratch** (F1=37.38%, RECT=66%)

**Implementa√ß√£o:**
```python
def stage2_ensemble(block):
    pred_ulmfit = ulmfit_model(block)   # F1=46.51%
    pred_scratch = scratch_model(block) # F1=37.38%
    
    # Weighted voting (ULMFiT > Scratch em AB)
    weights_ulmfit = {'SPLIT': 0.5, 'RECT': 0.4, 'AB': 0.7}
    weights_scratch = {'SPLIT': 0.5, 'RECT': 0.6, 'AB': 0.3}
    
    return weighted_vote(pred_ulmfit, pred_scratch, weights_ulmfit, weights_scratch)
```

**Vantagens:**
- ‚úÖ Combina for√ßas (AB de ULMFiT + RECT de Scratch)
- ‚úÖ Ensemble boost: +2-5% t√≠pico
- ‚úÖ Usa modelos j√° treinados

**Desvantagens:**
- ‚ö†Ô∏è Lat√™ncia 2x (dupla infer√™ncia)
- ‚ö†Ô∏è Complexidade no pipeline

**Expectativa:** F1=48-50%

### Op√ß√£o C: Adapters (Se Ensemble Falhar)

**√öltima op√ß√£o:** 2-3 dias implementa√ß√£o, alta complexidade.

## üìù Pr√≥ximos Passos (Ordem de Execu√ß√£o - ATUALIZADO)

### ‚úÖ Fase 1: Resolver Stage 2 (CONCLU√çDA)
1. ‚úÖ Decidir entre Op√ß√£o 1, 2, 3 ou 4 ‚Üí **Op√ß√£o 1 testada**
2. ‚úÖ Implementar Op√ß√£o 1 ‚Üí **Conclu√≠da**
3. ‚úÖ Treinar Stage 2 from scratch ‚Üí **F1=37.38% (√©poca 26)**
4. ‚úÖ Validar resultados ‚Üí **Frozen (46.51%) > Scratch (37.38%)**
5. ‚úÖ Decis√£o final ‚Üí **Usar OP√á√ÉO 2: Frozen Model**

### üéØ Fase 2: Re-executar Pipeline (EM ANDAMENTO)
6. ‚è≥ Script 008: Pipeline evaluation com **frozen model (√©poca 8)**
   - Usar checkpoint: `stage2_model_block16_classweights_ep8.pt`
   - Expectativa: Accuracy > 48%, F1 > 45%
7. ‚è≥ Analisar resultados pipeline completo
8. ‚è≥ Se falhar: Considerar Ensemble (Op√ß√£o D)
9. ‚è≥ Ajustar threshold se necess√°rio (script 007)

### üìä Fase 3: Documenta√ß√£o e Compara√ß√£o
10. ‚è≥ Atualizar documenta√ß√£o com decis√£o final
11. ‚è≥ Script 009: Compara√ß√£o v5 vs v6 (se pipeline passar)
12. ‚è≥ Documentar resultados finais para tese
13. ‚è≥ Atualizar README.md com pipeline completo

---
cp pesquisa_v6/scripts/004_train_stage2_redesigned.py \
   pesquisa_v6/scripts/004_train_stage2_redesigned_BACKUP.py

# 2. Modificar script 004 (comentar linha 283)
# ANTES:
#   checkpoint_stage1 = torch.load(...)
#   model.backbone.load_state_dict(checkpoint_stage1['model_state_dict'])
# DEPOIS:
#   # Usando apenas ImageNet pretrained (ResNet-18 padr√£o)
#   # N√£o carregar Stage 1 devido a negative transfer

# 3. Executar treinamento
source .venv/bin/activate
python pesquisa_v6/scripts/004_train_stage2_redesigned.py

# 4. Esperar ~2h (30 epochs)

# 5. Validar resultados:
#    - F1 frozen (√©pocas 1-8): esperar ~40-45%
#    - F1 unfrozen (√©pocas 9-30): esperar ~50-55%
#    - SEM degrada√ß√£o ao unfreeze

# 6. Se F1 ‚â• 50%, prosseguir para script 008 (pipeline)
```

---

## üìù Pr√≥ximos Passos (Ordem de Execu√ß√£o)

### Fase 1: Resolver Stage 2 (CR√çTICO)
1. ‚úÖ Decidir entre Op√ß√£o 1, 2, 3 ou 4
2. ‚è≥ Implementar Op√ß√£o 1 (5 minutos)
3. ‚è≥ Treinar Stage 2 from scratch (2 horas)
4. ‚è≥ Validar F1 ‚â• 50%

### Fase 2: Re-executar Pipeline
5. ‚è≥ Script 008: Pipeline evaluation com novo Stage 2
   - Expectativa: F1 > 45%, Accuracy > 48%
6. ‚è≥ Analisar resultados pipeline completo
7. ‚è≥ Ajustar threshold se necess√°rio (script 007)

### Fase 3: Compara√ß√£o v5 vs v6
8. ‚è≥ Script 009: Compara√ß√£o de desempenho
9. ‚è≥ Documentar resultados finais
10. ‚è≥ Atualizar README.md com pipeline completo

---

## üî¨ Refer√™ncias Cient√≠ficas Utilizadas

### Papers Fundamentais (Diagn√≥stico do Problema)

1. **Yosinski, J., et al. (2014).** "How transferable are features in deep neural networks?"  
   *NIPS 2014*  
   ‚Üí Negative transfer entre tasks diferentes  
   ‚Üí **Aplica√ß√£o:** Identifica√ß√£o do problema Stage 1‚ÜíStage 2

2. **Goodfellow, I. J., et al. (2013).** "An Empirical Investigation of Catastrophic Forgetting"  
   *arXiv:1312.6211*  
   ‚Üí Catastrophic forgetting em redes neurais  
   ‚Üí **Aplica√ß√£o:** Explica√ß√£o da degrada√ß√£o ao unfreeze

3. **Raghu, M., et al. (2019).** "Transfusion: Understanding Transfer Learning for Medical Imaging"  
   *NeurIPS 2019*  
   ‚Üí Frozen features √†s vezes s√£o superiores  
   ‚Üí **Aplica√ß√£o:** ‚úÖ **Validado** - Frozen (46.51%) > Unfrozen (34-37%)

### Papers Testados (T√©cnicas Experimentadas)

4. **Kornblith, S., et al. (2019).** "Do Better ImageNet Models Transfer Better?"  
   *CVPR 2019*  
   ‚Üí Nem sempre transfer learning melhora  
   ‚Üí **Aplica√ß√£o:** ‚úÖ **Validado** - ImageNet permite fine-tuning mas F1 menor

5. **Howard, J., & Ruder, S. (2018).** "Universal Language Model Fine-tuning for Text Classification"  
   *ACL 2018*  
   ‚Üí ULMFiT: gradual unfreezing + discriminative LR  
   ‚Üí **Aplica√ß√£o:** ‚ùå **Falhou** - N√£o preveniu catastrophic forgetting

6. **M√ºller, R., et al. (2019).** "When Does Label Smoothing Help?"  
   *NeurIPS 2019*  
   ‚Üí Conflito label smoothing + Focal Loss  
   ‚Üí **Aplica√ß√£o:** ‚ùå **N√£o resolveu** - Problema n√£o era loss function

### Papers de Suporte (Loss Functions e T√©cnicas)

7. **Cui, Y., et al. (2019).** "Class-Balanced Loss Based on Effective Number of Samples"  
   *CVPR 2019*  
   ‚Üí CB-Focal Loss para long-tail  
   ‚Üí **Aplica√ß√£o:** Usado em todos os experimentos

8. **Loshchilov, I., & Hutter, F. (2017).** "SGDR: Stochastic Gradient Descent with Warm Restarts"  
   *ICLR 2017*  
   ‚Üí Cosine annealing scheduler  
   ‚Üí **Aplica√ß√£o:** Usado mas n√£o resolveu CF

9. **He, K., et al. (2019).** "Rethinking ImageNet Pre-training"  
   *ICCV 2019*  
   ‚Üí Training from scratch pode igualar transfer learning  
   ‚Üí **Aplica√ß√£o:** ‚ö†Ô∏è **Parcialmente validado** - Sem CF mas F1 menor

### Papers N√£o Testados (Op√ß√µes Futuras)

10. **Rebuffi, S. A., et al. (2017).** "Learning multiple visual domains with residual adapters"  
    *NeurIPS 2017*  
    ‚Üí Adapter layers para multi-domain learning  
    ‚Üí **Status:** Op√ß√£o C - N√£o testado (alta complexidade)

11. **Houlsby, N., et al. (2019).** "Parameter-Efficient Transfer Learning for NLP"  
    *ICML 2019*  
    ‚Üí Adapters para transfer learning eficiente  
    ‚Üí **Status:** Op√ß√£o C - N√£o testado

12. **Dietterich, T. G. (2000).** "Ensemble Methods in Machine Learning"  
    *MCS 2000*  
    ‚Üí Teoria de ensembles  
    ‚Üí **Status:** Op√ß√£o D - Planejado se pipeline falhar

---

## üìö Documenta√ß√£o Detalhada (Tese de Doutorado)

**Localiza√ß√£o:** `pesquisa_v6/docs_v6/`

1. **`00_README.md`:** Estrutura geral da documenta√ß√£o
2. **`01_problema_negative_transfer.md`:** An√°lise do problema (580 linhas)
3. **`03_experimento_ulmfit.md`:** Experimento 1 - ULMFiT (450 linhas)
4. **`04_experimento_train_from_scratch.md`:** Experimento 2 - Train from Scratch (700+ linhas)

**Total:** ~2000 linhas de documenta√ß√£o t√©cnico-cient√≠fica

---

## ‚úÖ Status Final (13 de outubro de 2025)

| Item | Status | F1/Accuracy | Pr√≥xima A√ß√£o |
|------|--------|-------------|--------------|
| **Stage 1** | ‚úÖ Conclu√≠do | F1=72.28% | Nenhuma (meta atingida) |
| **Stage 2** | ‚úÖ **RESOLVIDO** | **F1=46.51% (frozen)** | Usar no pipeline |
| **Stage 3-RECT** | ‚úÖ Conclu√≠do | F1=68.44% | Nenhuma |
| **Stage 3-AB** | ‚úÖ Conclu√≠do | F1=24.50% | Nenhuma |
| **Threshold** | ‚úÖ Conclu√≠do | F1=72.79% | Nenhuma |
| **Pipeline (008)** | ‚è≥ **PR√ìXIMO** | Esperado >48% | Executar com frozen model |
| **Compara√ß√£o (009)** | ‚è∏Ô∏è Aguardando | - | Ap√≥s pipeline passar |

**Decis√£o Final:**
> **Usar Stage 2 Frozen Model (√©poca 8, F1=46.51%) no pipeline completo. Op√ß√£o 1 (Train from Scratch) testada mas inferior. Se pipeline falhar, considerar Ensemble (Op√ß√£o D).**

**Branch de Experimenta√ß√£o:** `feat/stage2-train-from-scratch` (commit `8538f01`)  
**Pr√≥ximo passo:** Merge para `main` e executar script 008 com modelo frozen.

---

**√öltima atualiza√ß√£o:** 13 de outubro de 2025  
**Status:** Experimentos conclu√≠dos - Decis√£o baseada em evid√™ncias  
   ‚Üí CB-Focal Loss para long-tail

8. **Loshchilov, I., & Hutter, F. (2017).** "SGDR: Stochastic Gradient Descent with Warm Restarts"  
   *ICLR 2017*  
   ‚Üí Cosine annealing scheduler

9. **He, K., et al. (2019).** "Rethinking ImageNet Pre-training"  
   *ICCV 2019*  
   ‚Üí Training from scratch pode igualar transfer learning

10. **Rebuffi, S. A., et al. (2017).** "Learning multiple visual domains with residual adapters"  
    *NeurIPS 2017*  
    ‚Üí Adapter layers para multi-domain learning

---

## üìÇ Arquivos Relevantes

### Scripts Treinamento
- `pesquisa_v6/scripts/003_train_stage1.py` - Stage 1 (F1=72.28% ‚úÖ)
- `pesquisa_v6/scripts/004_train_stage2_redesigned.py` - **MODIFICAR AQUI** ‚ö†Ô∏è
- `pesquisa_v6/scripts/005_train_stage3_rect.py` - Stage 3-RECT (F1=68.44% ‚úÖ)
- `pesquisa_v6/scripts/006_train_stage3_ab_fgvc.py` - Stage 3-AB (F1=24.50% ‚úÖ)

### Scripts Avalia√ß√£o
- `pesquisa_v6/scripts/007_optimize_threshold.py` - Threshold 0.45 ‚úÖ
- `pesquisa_v6/scripts/008_run_pipeline_eval_v6.py` - Pipeline (BLOQUEADO)
- `pesquisa_v6/scripts/009_compare_v5_v6.py` - Compara√ß√£o (BLOQUEADO)

### Modelos Salvos
- `pesquisa_v6/logs/v6_experiments/stage1/stage1_model_best.pt` ‚úÖ
- `pesquisa_v6/logs/v6_experiments/stage2/stage2_model_best.pt` ‚ö†Ô∏è (√©poca 1, frozen)
- `pesquisa_v6/logs/v6_experiments/stage3_rect/stage3_rect_model_best.pt` ‚úÖ
- `pesquisa_v6/logs/v6_experiments/stage3_ab/stage3_ab_fgvc_model_best.pt` ‚úÖ

### Hist√≥ricos Treinamento
- `pesquisa_v6/logs/v6_experiments/stage2/stage2_history.pt` - 30 epochs completos
  - √âpoca 1: F1=46.51% (frozen)
  - √âpocas 9-30: F1=32-36% (unfrozen, degradado)

---

## üí° Insights Aprendidos

### ‚úÖ O que funcionou
1. **Stage 1:** Transfer learning de ImageNet ‚Üí Binary task funcionou perfeitamente
2. **Stage 3:** Fine-tuning espec√≠fico para cada tipo de parti√ß√£o (RECT, AB) eficaz
3. **FGVC Model:** Arquitetura com bilinear pooling melhorou classifica√ß√£o fine-grained
4. **CB-Focal Loss:** Lidou bem com long-tail distribution
5. **Threshold Optimization:** Ajuste fino melhorou F1 de 72.28% ‚Üí 72.79%

### ‚ùå O que N√ÉO funcionou
1. **Stage 1 ‚Üí Stage 2 Transfer:** Negative transfer entre binary e multi-class
2. **ULMFiT sozinho:** N√£o previne catastrophic forgetting quando tasks s√£o diferentes
3. **Discriminative LR extremo:** Mesmo 500x de diferen√ßa n√£o evitou degrada√ß√£o
4. **Label Smoothing:** Conflito com Focal Loss (paper M√ºller et al.)
5. **Unfreezing gradual:** Problema n√£o √© velocidade, mas compatibilidade de tasks

### üî¨ Li√ß√µes para Pesquisa
1. **Task Similarity √© CR√çTICO:** Avaliar similaridade antes de transfer learning
2. **Nem sempre transfer > scratch:** Kornblith et al. confirmado empiricamente
3. **Literatura √© essencial:** Evitou tentativas aleat√≥rias, focou em solu√ß√µes validadas
4. **Monitoramento ativo:** Detectar degrada√ß√£o cedo evita desperd√≠cio de compute
5. **Pipelines hier√°rquicos:** Cada stage precisa ser independente ou muito similar

---

## üéØ Crit√©rios de Sucesso

### Stage 2 (ap√≥s reimplementa√ß√£o)
- [ ] F1 ‚â• 50% (target: 50-55%)
- [ ] SPLIT F1 ‚â• 40%
- [ ] RECT F1 ‚â• 55%
- [ ] AB F1 ‚â• 45%
- [ ] **SEM degrada√ß√£o** ao unfreeze (F1 unfrozen ‚â• F1 frozen)

### Pipeline Completo (script 008)
- [ ] Macro F1 ‚â• 45%
- [ ] Accuracy ‚â• 48%
- [ ] NONE: Precision/Recall ‚â• 70%
- [ ] SPLIT: F1 ‚â• 35%
- [ ] RECT: F1 ‚â• 50%
- [ ] AB: F1 ‚â• 40%

### Compara√ß√£o v5 vs v6 (script 009)
- [ ] v6 F1 ‚â• v5 F1
- [ ] v6 SPLIT F1 > v5 SPLIT F1 (foco principal)
- [ ] Documenta√ß√£o completa dos resultados

---

## üìÖ Estimativa de Tempo

| Tarefa | Tempo Estimado |
|--------|----------------|
| Implementar Op√ß√£o 1 | 5 minutos |
| Treinar Stage 2 (30 epochs) | 2 horas |
| Analisar resultados | 15 minutos |
| Re-executar Pipeline 008 | 30 minutos |
| Documentar resultados | 30 minutos |
| Script 009 compara√ß√£o | 1 hora |
| **TOTAL** | **~4.5 horas** |

---

## üîÑ Hist√≥rico de Decis√µes

### 2025-10-07: Diagn√≥stico Negative Transfer
- **Problema:** Stage 2 degrada de 46.51% ‚Üí 32-36% ao unfreeze
- **Tentativas:** 5 t√©cnicas da literatura (ULMFiT, etc.) - todas falharam
- **Diagn√≥stico:** Negative transfer (Yosinski et al., 2014)
- **Decis√£o:** Recomendar train from scratch (Op√ß√£o 1)

### 2025-10-07: Implementa√ß√£o ULMFiT
- **Mudan√ßas:** 8 freeze epochs, discriminative LR (500x), remove label smoothing
- **Resultado:** F1 manteve em 46.51% (frozen), degradou igual
- **Conclus√£o:** Problema n√£o √© fine-tuning, mas inicializa√ß√£o

### 2025-10-06: Pipeline 008 Falha
- **Resultado:** F1=13.16%, Accuracy=47.14%
- **Causa:** Stage 2 salvo na √©poca 1 (47.58%) do treinamento original
- **Impacto:** Cascata de erros nos Stages 3

---

## üìå Notas Importantes

1. **Backup antes de modificar:** Sempre salvar vers√£o atual antes de mudan√ßas
2. **Validar hist√≥ria:** Checar `stage2_history.pt` ap√≥s treinamento
3. **Monitorar unfreezing:** Epochs 9-10 s√£o cr√≠ticas para detectar degrada√ß√£o
4. **Threshold pode mudar:** Se Stage 2 melhorar, re-otimizar threshold
5. **Pipeline depende de TODOS:** Um stage ruim quebra toda hierarquia

---

## üìß Contato

Para d√∫vidas ou discuss√£o sobre as op√ß√µes, revisar este documento antes de continuar.

**√öltima atualiza√ß√£o:** 07 de outubro de 2025  
**Vers√£o:** 2.0 - Diagn√≥stico Completo + Recomenda√ß√µes
