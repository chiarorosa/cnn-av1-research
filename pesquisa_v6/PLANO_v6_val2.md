# PLANO V6 - Valida√ß√£o 2: Resolu√ß√£o do Stage 2

**Data:** 07 de outubro de 2025  
**Status:** Stage 2 apresentando Negative Transfer - necess√°ria reimplementa√ß√£o

---

## üìã Resumo Executivo

### Progresso Atual
- ‚úÖ **Scripts 001-002:** Dataset preparado (152,600 train / 38,256 val)
- ‚úÖ **Script 003 (Stage 1):** F1=72.28% (√©poca 19) - **META ATINGIDA** ‚â•68%
- ‚ö†Ô∏è **Script 004 (Stage 2):** F1=46.51% (frozen) ‚Üí 32-36% (unfrozen) - **PROBLEMA CR√çTICO**
- ‚úÖ **Script 005 (Stage 3-RECT):** F1=68.44% (√©poca 12)
- ‚úÖ **Script 006 FGVC (Stage 3-AB):** F1=24.50% (4/4 classes, √©poca 6)
- ‚úÖ **Script 007 (Threshold):** threshold=0.45 ‚Üí F1=72.79%
- ‚ùå **Script 008 (Pipeline):** F1=13.16% - **FALHA CASCATA** devido Stage 2
- ‚è∏Ô∏è **Script 009:** Bloqueado at√© resolu√ß√£o do Stage 2

### Meta Global
- Stage 1: F1 ‚â• 68% ‚úÖ **72.28%**
- Stage 2: F1 ‚â• 45% ‚ö†Ô∏è **46.51% (frozen only)**
- Pipeline Final: Accuracy ‚â• 48% ‚ùå **47.14% (pipeline quebrado)**

---

## üî¥ Problema Cr√≠tico: Stage 2 Catastrophic Forgetting

### Sintomas Observados

**Treinamento Original (antes ULMFiT):**
- √âpoca 1 (frozen): F1=**47.58%** ‚úÖ
- √âpoca 3 (unfrozen): F1=**34-38%** ‚ùå
- Modelo salvo na √©poca 1, causando falha do pipeline

**Treinamento com ULMFiT (atual):**
```
√âpoca 1-8 (FROZEN):
  Best: F1=46.51% (√©poca 1)
  - SPLIT: 40.75%
  - RECT: 60.66%
  - AB: 38.13%

üîì Unfreezing backbone com Discriminative LR (√©poca 9)
   Head LR: 5e-4
   Backbone LR: 1e-6 (500x menor)

√âpoca 9-30 (UNFROZEN):
  F1=32-36% (oscilando)
  - SPLIT: 22% (degradou de 40%)
  - RECT: 37% (degradou de 60%)
  - AB: 42% (vari√°vel)
```

### T√©cnicas Tentadas (TODAS FALHARAM)

Implementamos **5 t√©cnicas da literatura** sem sucesso:

1. **ULMFiT** (Howard & Ruder, 2018)
   - Gradual unfreezing: 8 √©pocas frozen ‚Üí unfreezing
   - ‚ùå N√£o preveniu catastrophic forgetting

2. **Discriminative Fine-tuning** (Howard & Ruder, 2018)
   - Head LR: 5e-4
   - Backbone LR: 1e-6 (500x menor)
   - ‚ùå Mesmo com LR baix√≠ssimo, backbone degrada

3. **Remo√ß√£o de Label Smoothing** (M√ºller et al., 2019)
   - Paper: "When Does Label Smoothing Help?"
   - Conflito com Focal Loss removido
   - ‚ùå N√£o resolveu o problema

4. **Cosine Annealing** (Loshchilov & Hutter, 2017 - SGDR)
   - LR scheduling suave para melhor converg√™ncia
   - ‚ùå Converg√™ncia n√£o √© o problema

5. **ClassBalancedFocalLoss Device Fix** (Cui et al., 2019)
   - CB-beta=0.9999, gamma=2.0
   - Bug de device corrigido
   - ‚ùå Loss n√£o era o problema

---

## üî¨ Diagn√≥stico Baseado em Literatura

### Negative Transfer (Yosinski et al., 2014)

**Paper:** "How transferable are features in deep neural networks?"

**Conceito-chave:**
- Transfer learning funciona quando **source task** e **target task** s√£o similares
- Transfer learning **PREJUDICA** quando tasks s√£o diferentes
- Features de layers finais s√£o **task-specific**

### An√°lise Task Similarity: Stage 1 vs Stage 2

| Aspecto | Stage 1 | Stage 2 |
|---------|---------|---------|
| **Task** | Binary (NONE vs PARTITION) | 3-way (SPLIT vs RECT vs AB) |
| **Features necess√°rias** | "Tem parti√ß√£o?" | "Tipo de parti√ß√£o?" |
| **Foco visual** | Detec√ß√£o de bordas de parti√ß√£o | Padr√µes de divis√£o geom√©trica |
| **Distribui√ß√£o** | 50/50 balanceado | Long-tail (SPLIT minorit√°ria) |
| **Complexidade** | Simples (presen√ßa/aus√™ncia) | Complexa (geometria) |

**Conclus√£o:** Tasks s√£o **FUNDAMENTALMENTE DIFERENTES**

### Por que Backbone do Stage 1 Prejudica?

1. **Feature Specialization:**
   - Stage 1 backbone aprendeu a detectar "presen√ßa de particionamento"
   - Essas features suprimem padr√µes geom√©tricos necess√°rios para Stage 2
   
2. **Confirmation Bias:**
   - Kornblith et al., 2019: "Do Better ImageNet Models Transfer Better?"
   - Nem sempre transfer learning melhora performance
   - √Äs vezes, features gen√©ricas (ImageNet) > features espec√≠ficas (Stage 1)

3. **Catastrophic Forgetting:**
   - Goodfellow et al., 2013
   - Quando tentamos unfreeze, backbone tenta adaptar
   - Features do Stage 1 s√£o destru√≠das, mas novas features n√£o convergem

---

## üéØ Solu√ß√µes Propostas (Baseadas em Literatura)

### OP√á√ÉO 1: Train from Scratch ‚≠ê **RECOMENDADA**

**Refer√™ncias:**
- Kornblith et al., 2019: "Do Better ImageNet Models Transfer Better?"
- He et al., 2019: "Rethinking ImageNet Pre-training"

**Implementa√ß√£o:**
```python
# ANTES (linha 283 do script 004):
checkpoint_stage1 = torch.load(stage1_model_path, ...)
model.backbone.load_state_dict(checkpoint_stage1['model_state_dict'])

# DEPOIS:
# Comentar linha acima - usar apenas ImageNet pretrained
# ResNet-18 com pretrained=True j√° foi inicializado na cria√ß√£o do modelo
```

**Par√¢metros mantidos:**
- CB-Focal Loss (beta=0.9999, gamma=2.0)
- ULMFiT: 8 freeze epochs + discriminative LR
- Cosine Annealing scheduler
- 30 epochs total

**Expectativa:**
- F1 baseline (√©poca 1 frozen): ~40-45%
- F1 ap√≥s unfreezing: ~50-55% ‚úÖ (sem catastrophic forgetting)
- Motivo: Backbone aprende features espec√≠ficas para 3-way desde o in√≠cio

**Vantagens:**
- ‚úÖ Elimina conflito de features Stage 1 vs Stage 2
- ‚úÖ ImageNet features s√£o gen√©ricas (edges, textures, shapes)
- ‚úÖ Permite unfreezing sem degrada√ß√£o
- ‚úÖ Implementa√ß√£o simples (comentar 1 linha)
- ‚úÖ Base cient√≠fica s√≥lida

**Desvantagens:**
- ‚ö†Ô∏è Requer novo treinamento completo (30 epochs, ~2h)
- ‚ö†Ô∏è Pode ter baseline levemente menor (mas melhora depois)

---

### OP√á√ÉO 2: Frozen-Only Model

**Refer√™ncias:**
- Raghu et al., 2019: "Transfusion: Understanding Transfer Learning"
- Mostra que frozen features √†s vezes s√£o superiores

**Implementa√ß√£o:**
- Usar modelo da **√©poca 1** (F1=46.51%)
- **NUNCA** fazer unfreezing do backbone
- Aceitar limita√ß√£o

**Vantagens:**
- ‚úÖ Modelo pronto AGORA
- ‚úÖ F1=46.51% j√° atinge meta ‚â•45%
- ‚úÖ Sem necessidade de retreinamento

**Desvantagens:**
- ‚ùå Limita potencial de melhoria
- ‚ùå N√£o resolve problema conceitual
- ‚ùå Backbone Stage 1 sempre ser√° sub√≥timo para Stage 2

---

### OP√á√ÉO 3: Hybrid Approach com Adapters

**Refer√™ncias:**
- Rebuffi et al., 2017: "Learning multiple visual domains with residual adapters"
- Houlsby et al., 2019: "Parameter-Efficient Transfer Learning"

**Implementa√ß√£o:**
- Adicionar adapter layers entre backbone e head
- Treinar apenas adapters (backbone Stage 1 frozen)
- Permite adapta√ß√£o sem modificar backbone

**Vantagens:**
- ‚úÖ Mant√©m conhecimento do Stage 1
- ‚úÖ Adapta para Stage 2 sem catastrophic forgetting

**Desvantagens:**
- ‚ùå Complexidade arquitetural alta
- ‚ùå Requer refatora√ß√£o do modelo
- ‚ùå Valida√ß√£o cient√≠fica incerta para este caso

---

### OP√á√ÉO 4: Redesenhar Hierarquia

**Refer√™ncias:**
- Sun et al., 2017: "Revisiting Unreasonable Effectiveness of Data"

**Implementa√ß√£o:**
- Treinar Stage 2 direto nos dados ORIGINAIS (sem filtro Stage 1)
- Eliminar depend√™ncia hier√°rquica
- Usar Stage 1 apenas para roteamento no pipeline

**Vantagens:**
- ‚úÖ Stage 2 v√™ todos os dados (n√£o s√≥ PARTITION)
- ‚úÖ Elimina vi√©s do Stage 1

**Desvantagens:**
- ‚ùå Quebra conceito hier√°rquico do PLANO_V6.md
- ‚ùå Stage 2 precisa aprender a ignorar NONE (ru√≠do)
- ‚ùå Aumenta complexidade do dataset

---

## üìä Compara√ß√£o das Op√ß√µes

| Crit√©rio | Op√ß√£o 1 (Scratch) | Op√ß√£o 2 (Frozen) | Op√ß√£o 3 (Adapters) | Op√ß√£o 4 (Redesign) |
|----------|-------------------|------------------|--------------------|--------------------|
| **Implementa√ß√£o** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Simples | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Imediata | ‚≠ê‚≠ê Complexa | ‚≠ê‚≠ê‚≠ê Moderada |
| **Base Cient√≠fica** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Forte | ‚≠ê‚≠ê‚≠ê‚≠ê Razo√°vel | ‚≠ê‚≠ê‚≠ê‚≠ê V√°lida | ‚≠ê‚≠ê‚≠ê Especulativa |
| **F1 Esperado** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê 50-55% | ‚≠ê‚≠ê‚≠ê 46.51% | ‚≠ê‚≠ê‚≠ê‚≠ê 48-52% | ‚≠ê‚≠ê‚≠ê‚≠ê 48-53% |
| **Tempo Implementa√ß√£o** | 5 min + 2h treino | 0 min | 2-3 dias | 1 dia |
| **Risco** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Baixo | ‚≠ê‚≠ê‚≠ê‚≠ê Baixo | ‚≠ê‚≠ê‚≠ê M√©dio | ‚≠ê‚≠ê Alto |
| **Alinhamento PLANO_V6** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Total | ‚≠ê‚≠ê‚≠ê‚≠ê Bom | ‚≠ê‚≠ê‚≠ê‚≠ê Bom | ‚≠ê‚≠ê Requer revis√£o |

---

## üöÄ Recomenda√ß√£o Final

### **OP√á√ÉO 1: Train from Scratch** ‚≠ê

**Raz√µes:**
1. **Base cient√≠fica s√≥lida:** Kornblith et al. (2019) mostrou que ImageNet pretrained √†s vezes > task-specific transfer
2. **Simplicidade:** 1 linha de c√≥digo comentada
3. **Melhor F1 esperado:** 50-55% (vs 46.51% atual)
4. **Resolve problema raiz:** Elimina negative transfer
5. **Permite unfreezing:** Sem catastrophic forgetting

**Plano de A√ß√£o:**

```bash
# 1. Backup do script atual
cp pesquisa_v6/scripts/004_train_stage2_redesigned.py \
   pesquisa_v6/scripts/004_train_stage2_redesigned_BACKUP.py

# 2. Modificar script 004 (comentar linha 283)
# ANTES:
#   checkpoint_stage1 = torch.load(...)
#   model.backbone.load_state_dict(checkpoint_stage1['model_state_dict'])
# DEPOIS:
#   # Usando apenas ImageNet pretrained (ResNet-18 padr√£o)
#   # N√£o carregar Stage 1 devido a negative transfer

# 3. Executar treinamento
source .venv/bin/activate
python pesquisa_v6/scripts/004_train_stage2_redesigned.py

# 4. Esperar ~2h (30 epochs)

# 5. Validar resultados:
#    - F1 frozen (√©pocas 1-8): esperar ~40-45%
#    - F1 unfrozen (√©pocas 9-30): esperar ~50-55%
#    - SEM degrada√ß√£o ao unfreeze

# 6. Se F1 ‚â• 50%, prosseguir para script 008 (pipeline)
```

---

## üìù Pr√≥ximos Passos (Ordem de Execu√ß√£o)

### Fase 1: Resolver Stage 2 (CR√çTICO)
1. ‚úÖ Decidir entre Op√ß√£o 1, 2, 3 ou 4
2. ‚è≥ Implementar Op√ß√£o 1 (5 minutos)
3. ‚è≥ Treinar Stage 2 from scratch (2 horas)
4. ‚è≥ Validar F1 ‚â• 50%

### Fase 2: Re-executar Pipeline
5. ‚è≥ Script 008: Pipeline evaluation com novo Stage 2
   - Expectativa: F1 > 45%, Accuracy > 48%
6. ‚è≥ Analisar resultados pipeline completo
7. ‚è≥ Ajustar threshold se necess√°rio (script 007)

### Fase 3: Compara√ß√£o v5 vs v6
8. ‚è≥ Script 009: Compara√ß√£o de desempenho
9. ‚è≥ Documentar resultados finais
10. ‚è≥ Atualizar README.md com pipeline completo

---

## üî¨ Refer√™ncias Cient√≠ficas Utilizadas

1. **Yosinski, J., et al. (2014).** "How transferable are features in deep neural networks?"  
   *NIPS 2014*  
   ‚Üí Negative transfer entre tasks diferentes

2. **Kornblith, S., et al. (2019).** "Do Better ImageNet Models Transfer Better?"  
   *CVPR 2019*  
   ‚Üí Nem sempre transfer learning melhora

3. **Howard, J., & Ruder, S. (2018).** "Universal Language Model Fine-tuning for Text Classification"  
   *ACL 2018*  
   ‚Üí ULMFiT: gradual unfreezing + discriminative LR

4. **Goodfellow, I. J., et al. (2013).** "An Empirical Investigation of Catastrophic Forgetting"  
   *arXiv:1312.6211*  
   ‚Üí Catastrophic forgetting em redes neurais

5. **Raghu, M., et al. (2019).** "Transfusion: Understanding Transfer Learning for Medical Imaging"  
   *NeurIPS 2019*  
   ‚Üí Frozen features √†s vezes s√£o superiores

6. **M√ºller, R., et al. (2019).** "When Does Label Smoothing Help?"  
   *NeurIPS 2019*  
   ‚Üí Conflito label smoothing + Focal Loss

7. **Cui, Y., et al. (2019).** "Class-Balanced Loss Based on Effective Number of Samples"  
   *CVPR 2019*  
   ‚Üí CB-Focal Loss para long-tail

8. **Loshchilov, I., & Hutter, F. (2017).** "SGDR: Stochastic Gradient Descent with Warm Restarts"  
   *ICLR 2017*  
   ‚Üí Cosine annealing scheduler

9. **He, K., et al. (2019).** "Rethinking ImageNet Pre-training"  
   *ICCV 2019*  
   ‚Üí Training from scratch pode igualar transfer learning

10. **Rebuffi, S. A., et al. (2017).** "Learning multiple visual domains with residual adapters"  
    *NeurIPS 2017*  
    ‚Üí Adapter layers para multi-domain learning

---

## üìÇ Arquivos Relevantes

### Scripts Treinamento
- `pesquisa_v6/scripts/003_train_stage1.py` - Stage 1 (F1=72.28% ‚úÖ)
- `pesquisa_v6/scripts/004_train_stage2_redesigned.py` - **MODIFICAR AQUI** ‚ö†Ô∏è
- `pesquisa_v6/scripts/005_train_stage3_rect.py` - Stage 3-RECT (F1=68.44% ‚úÖ)
- `pesquisa_v6/scripts/006_train_stage3_ab_fgvc.py` - Stage 3-AB (F1=24.50% ‚úÖ)

### Scripts Avalia√ß√£o
- `pesquisa_v6/scripts/007_optimize_threshold.py` - Threshold 0.45 ‚úÖ
- `pesquisa_v6/scripts/008_run_pipeline_eval_v6.py` - Pipeline (BLOQUEADO)
- `pesquisa_v6/scripts/009_compare_v5_v6.py` - Compara√ß√£o (BLOQUEADO)

### Modelos Salvos
- `pesquisa_v6/logs/v6_experiments/stage1/stage1_model_best.pt` ‚úÖ
- `pesquisa_v6/logs/v6_experiments/stage2/stage2_model_best.pt` ‚ö†Ô∏è (√©poca 1, frozen)
- `pesquisa_v6/logs/v6_experiments/stage3_rect/stage3_rect_model_best.pt` ‚úÖ
- `pesquisa_v6/logs/v6_experiments/stage3_ab/stage3_ab_fgvc_model_best.pt` ‚úÖ

### Hist√≥ricos Treinamento
- `pesquisa_v6/logs/v6_experiments/stage2/stage2_history.pt` - 30 epochs completos
  - √âpoca 1: F1=46.51% (frozen)
  - √âpocas 9-30: F1=32-36% (unfrozen, degradado)

---

## üí° Insights Aprendidos

### ‚úÖ O que funcionou
1. **Stage 1:** Transfer learning de ImageNet ‚Üí Binary task funcionou perfeitamente
2. **Stage 3:** Fine-tuning espec√≠fico para cada tipo de parti√ß√£o (RECT, AB) eficaz
3. **FGVC Model:** Arquitetura com bilinear pooling melhorou classifica√ß√£o fine-grained
4. **CB-Focal Loss:** Lidou bem com long-tail distribution
5. **Threshold Optimization:** Ajuste fino melhorou F1 de 72.28% ‚Üí 72.79%

### ‚ùå O que N√ÉO funcionou
1. **Stage 1 ‚Üí Stage 2 Transfer:** Negative transfer entre binary e multi-class
2. **ULMFiT sozinho:** N√£o previne catastrophic forgetting quando tasks s√£o diferentes
3. **Discriminative LR extremo:** Mesmo 500x de diferen√ßa n√£o evitou degrada√ß√£o
4. **Label Smoothing:** Conflito com Focal Loss (paper M√ºller et al.)
5. **Unfreezing gradual:** Problema n√£o √© velocidade, mas compatibilidade de tasks

### üî¨ Li√ß√µes para Pesquisa
1. **Task Similarity √© CR√çTICO:** Avaliar similaridade antes de transfer learning
2. **Nem sempre transfer > scratch:** Kornblith et al. confirmado empiricamente
3. **Literatura √© essencial:** Evitou tentativas aleat√≥rias, focou em solu√ß√µes validadas
4. **Monitoramento ativo:** Detectar degrada√ß√£o cedo evita desperd√≠cio de compute
5. **Pipelines hier√°rquicos:** Cada stage precisa ser independente ou muito similar

---

## üéØ Crit√©rios de Sucesso

### Stage 2 (ap√≥s reimplementa√ß√£o)
- [ ] F1 ‚â• 50% (target: 50-55%)
- [ ] SPLIT F1 ‚â• 40%
- [ ] RECT F1 ‚â• 55%
- [ ] AB F1 ‚â• 45%
- [ ] **SEM degrada√ß√£o** ao unfreeze (F1 unfrozen ‚â• F1 frozen)

### Pipeline Completo (script 008)
- [ ] Macro F1 ‚â• 45%
- [ ] Accuracy ‚â• 48%
- [ ] NONE: Precision/Recall ‚â• 70%
- [ ] SPLIT: F1 ‚â• 35%
- [ ] RECT: F1 ‚â• 50%
- [ ] AB: F1 ‚â• 40%

### Compara√ß√£o v5 vs v6 (script 009)
- [ ] v6 F1 ‚â• v5 F1
- [ ] v6 SPLIT F1 > v5 SPLIT F1 (foco principal)
- [ ] Documenta√ß√£o completa dos resultados

---

## üìÖ Estimativa de Tempo

| Tarefa | Tempo Estimado |
|--------|----------------|
| Implementar Op√ß√£o 1 | 5 minutos |
| Treinar Stage 2 (30 epochs) | 2 horas |
| Analisar resultados | 15 minutos |
| Re-executar Pipeline 008 | 30 minutos |
| Documentar resultados | 30 minutos |
| Script 009 compara√ß√£o | 1 hora |
| **TOTAL** | **~4.5 horas** |

---

## üîÑ Hist√≥rico de Decis√µes

### 2025-10-07: Diagn√≥stico Negative Transfer
- **Problema:** Stage 2 degrada de 46.51% ‚Üí 32-36% ao unfreeze
- **Tentativas:** 5 t√©cnicas da literatura (ULMFiT, etc.) - todas falharam
- **Diagn√≥stico:** Negative transfer (Yosinski et al., 2014)
- **Decis√£o:** Recomendar train from scratch (Op√ß√£o 1)

### 2025-10-07: Implementa√ß√£o ULMFiT
- **Mudan√ßas:** 8 freeze epochs, discriminative LR (500x), remove label smoothing
- **Resultado:** F1 manteve em 46.51% (frozen), degradou igual
- **Conclus√£o:** Problema n√£o √© fine-tuning, mas inicializa√ß√£o

### 2025-10-06: Pipeline 008 Falha
- **Resultado:** F1=13.16%, Accuracy=47.14%
- **Causa:** Stage 2 salvo na √©poca 1 (47.58%) do treinamento original
- **Impacto:** Cascata de erros nos Stages 3

---

## üìå Notas Importantes

1. **Backup antes de modificar:** Sempre salvar vers√£o atual antes de mudan√ßas
2. **Validar hist√≥ria:** Checar `stage2_history.pt` ap√≥s treinamento
3. **Monitorar unfreezing:** Epochs 9-10 s√£o cr√≠ticas para detectar degrada√ß√£o
4. **Threshold pode mudar:** Se Stage 2 melhorar, re-otimizar threshold
5. **Pipeline depende de TODOS:** Um stage ruim quebra toda hierarquia

---

## üìß Contato

Para d√∫vidas ou discuss√£o sobre as op√ß√µes, revisar este documento antes de continuar.

**√öltima atualiza√ß√£o:** 07 de outubro de 2025  
**Vers√£o:** 2.0 - Diagn√≥stico Completo + Recomenda√ß√µes
