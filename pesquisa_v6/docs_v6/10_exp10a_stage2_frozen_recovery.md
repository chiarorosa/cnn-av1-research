# Experimento 10A: Recupera√ß√£o do Modelo Stage 2 Frozen

**Data:** 13-14 de outubro de 2025  
**Branch:** `feat/exp10a-recover-stage2-frozen`  
**Status:** ‚ùå **FALHOU** - Checkpoint n√£o confi√°vel  
**Prioridade:** üî¥ **CR√çTICA** - BLOQUEADOR (experimento falhou, bloqueio permanece)

---

## 1. Contexto e Motiva√ß√£o

### 1.1 Problema Identificado

Durante an√°lise do Script 009 (confusion matrix Stage 2), descobriu-se que **ambos os checkpoints** do Stage 2 est√£o colapsados:

**Checkpoint `stage2_model_best.pt`:**
- Prediz **RECT (classe 1) para 100%** das amostras
- Accuracy: 46.44% (= preval√™ncia de RECT no dataset)
- F1 macro: 0.21 (SPLIT=0.0, RECT=0.63, AB=0.0)

**Checkpoint `stage2_model_final.pt`:**
- Prediz **SPLIT (classe 0) para 99.99%** das amostras  
- Accuracy: 15.58%
- F1 macro: 0.09

### 1.2 An√°lise do History

An√°lise do `stage2_history.pt` revelou:

| √âpoca | Fase | Val F1 | Val Acc | Status |
|-------|------|--------|---------|--------|
| **0** | **Frozen** | **46.51%** | **48.9%** | ‚úÖ **MELHOR** |
| 1-7 | Frozen | 44-46% | 48-49% | ‚úÖ Est√°vel |
| **8** | **Unfreeze** | **34.39%** | **38.7%** | ‚ùå **COLAPSO** |
| 9-29 | Unfrozen | 33-37% | 38-42% | ‚ùå Nunca recuperou |

**Causa Identificada:** **Catastrophic Forgetting Severo** ao unfreeze do backbone (√©poca 7‚Üí8)

### 1.3 Hip√≥tese

> "O modelo frozen (√©poca 0) funciona corretamente (F1=46.51%, Acc=48.9%). Catastrophic forgetting ao unfreeze destruiu features. **Solu√ß√£o: usar modelo frozen exclusivamente.**"

**Fundamenta√ß√£o:**
- Kornblith et al. (2019): Features congeladas podem superar fine-tuning em tasks dissimilares
- Yosinski et al. (2014): Negative transfer ocorre quando source e target tasks s√£o diferentes
- Documentado em `docs_v6/01_problema_negative_transfer.md`

---

## 2. Objetivo do Experimento

**Recuperar checkpoint da √©poca 0 (frozen backbone) e validar sua funcionalidade.**

**Metas:**
1. ‚úÖ Treinar Stage 2 por 1 √©poca (frozen) com argumento `--save-epoch-0`
2. ‚è≥ Validar modelo com Script 009 (esperado: F1 ~46-47%, Acc ~48-49%)
3. ‚è≥ Re-avaliar pipeline completo com Stage 2 frozen
4. ‚è≥ Comparar com baseline Exp 09 (45.86% accuracy)

---

## 3. Implementa√ß√£o

### 3.1 Modifica√ß√µes no Script 004

**Arquivo:** `pesquisa_v6/scripts/004_train_stage2_redesigned.py`

**Mudan√ßa 1: Novo argumento CLI**
```python
parser.add_argument("--save-epoch-0", action="store_true",
                   help="Save checkpoint after epoch 0 (frozen backbone)")
```

**Mudan√ßa 2: Salvamento ap√≥s √©poca 0**
```python
# Save epoch 0 checkpoint (frozen backbone) if requested
if epoch == 0 and args.save_epoch_0:
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict(),
        'val_macro_f1': val_metrics['macro_f1'],
        'val_metrics': val_metrics,
    }, output_dir / "stage2_model_epoch0_frozen.pt")
    print(f"  üíæ Saved epoch 0 (frozen) checkpoint - F1: {val_metrics['macro_f1']:.2%}")
```

### 3.2 Comando de Execu√ß√£o

```bash
python3 pesquisa_v6/scripts/004_train_stage2_redesigned.py \
  --dataset-dir pesquisa_v6/v6_dataset/block_16 \
  --epochs 1 \
  --batch-size 128 \
  --output-dir pesquisa_v6/logs/v6_experiments/stage2_frozen_recovery \
  --device cuda \
  --save-epoch-0
```

**Status:** üü° Em execu√ß√£o (29% conclu√≠do)

---

## 4. Protocolo de Valida√ß√£o

### 4.1 Passo 1: An√°lise de Confusion Matrix (Script 009)

```bash
python3 pesquisa_v6/scripts/009_analyze_stage2_confusion.py \
  --stage2-model pesquisa_v6/logs/v6_experiments/stage2_frozen_recovery/stage2_model_epoch0_frozen.pt \
  --dataset-dir pesquisa_v6/v6_dataset/block_16 \
  --device cuda \
  --output pesquisa_v6/logs/v6_experiments/stage2_frozen_recovery/confusion_matrix.json
```

**Esperado:**
- F1 macro: 46-47%
- Accuracy: 48-49%
- Confusion matrix **n√£o-trivial** (n√£o 100% em uma classe)

### 4.2 Passo 2: Re-avaliar Pipeline Completo (Script 008)

```bash
python3 pesquisa_v6/scripts/008_run_pipeline_eval_v6.py \
  --stage1-model pesquisa_v6/logs/v6_experiments/stage1/stage1_model_best.pt \
  --stage2-model pesquisa_v6/logs/v6_experiments/stage2_frozen_recovery/stage2_model_epoch0_frozen.pt \
  --stage3-rect-model pesquisa_v6/logs/test_noise_injection/stage3_rect_robust.pt \
  --stage3-ab-models \
      pesquisa_v6/logs/test_noise_injection_ab/stage3_ab_robust.pt \
      pesquisa_v6/logs/test_noise_injection_ab/stage3_ab_robust.pt \
      pesquisa_v6/logs/test_noise_injection_ab/stage3_ab_robust.pt \
  --output-dir pesquisa_v6/logs/v6_experiments/pipeline_eval_stage2_frozen
```

**Compara√ß√£o com Baseline Exp 09:**
| M√©trica | Exp 09 (S2 colapsado) | Exp 10A (S2 frozen) | Esperado Œî |
|---------|----------------------|---------------------|------------|
| Accuracy | 45.86% | ? | +1 a +2pp |
| HORZ F1 | 23.94% | ? | +5 a +10pp |
| VERT F1 | 19.36% | ? | Manter |
| HORZ_A F1 | 0.00% | ? | +10 a +20pp |
| VERT_A F1 | 15.25% | ? | +5 a +10pp |

---

## 5. Resultados

### 5.1 Fase 1: Treinamento (‚úÖ Sucesso)

**Comando Executado:**
```bash
python3 pesquisa_v6/scripts/004_train_stage2_redesigned.py \
  --dataset-dir pesquisa_v6/v6_dataset/block_16 \
  --epochs 1 \
  --batch-size 128 \
  --output-dir pesquisa_v6/logs/v6_experiments/stage2_frozen_recovery_v2 \
  --device cuda \
  --save-epoch-0 \
  --stage1-model pesquisa_v6/logs/v6_experiments/stage1/stage1_model_best.pt
```

**Observa√ß√£o Cr√≠tica:** Primeira tentativa **sem** `--stage1-model` resultou em F1=8.99%. Segundo treinamento **com** Stage 1 backbone teve sucesso.

**M√©tricas Durante Treinamento (√âpoca 1):**
| M√©trica | Valor | Status |
|---------|-------|--------|
| Val Accuracy | **51.19%** | ‚úÖ Superou esperado 48.9% |
| Val Macro F1 | **48.52%** | ‚úÖ Superou esperado 46.51% |
| F1 SPLIT | **41.68%** | ‚úÖ Funcional |
| F1 RECT | **62.14%** | ‚úÖ Funcional |
| F1 AB | **41.73%** | ‚úÖ Funcional |

**Conclus√£o Fase 1:** ‚úÖ Modelo frozen funciona corretamente durante training. **+2.01pp F1** sobre esperado.

### 5.2 Fase 2: Valida√ß√£o Standalone (‚ùå **FALHOU**)

**Comando Executado (Script 009):**
```bash
python3 pesquisa_v6/scripts/009_analyze_stage2_confusion.py \
  --stage2-model .../stage2_model_epoch1_frozen.pt \
  --dataset-dir pesquisa_v6/v6_dataset/block_16 \
  --device cuda
```

**M√©tricas Ap√≥s Carregamento:**
| M√©trica | Treino (Fase 1) | Inference (Fase 2) | Delta |
|---------|-----------------|-------------------|-------|
| Val Accuracy | **51.19%** | **46.69%** | **-4.50pp** ‚ùå |
| Val Macro F1 | **48.52%** | **25.90%** | **-22.62pp** ‚ùå‚ùå‚ùå |
| F1 SPLIT | **41.68%** | **13.01%** | **-28.67pp** ‚ùå |
| F1 RECT | **62.14%** | **64.70%** | +2.56pp |
| F1 AB | **41.73%** | **0.00%** | **-41.73pp** ‚ùå‚ùå‚ùå |

**Confusion Matrix:**
```
     Pred: SPLIT    RECT      AB
GT SPLIT:    551    5411       0
GT RECT :    453   17311       1
GT AB   :   1504   13025       0
```

**An√°lise:**
- Modelo prediz **apenas 13 samples como SPLIT** (0.03% do dataset)
- Modelo prediz **apenas 1 sample como AB** (0.0025% do dataset)
- **97.44% recall de RECT** - modelo est√° em modo trivial "prediz tudo como RECT"

### 5.3 Investiga√ß√£o do Problema

**Teste Diagn√≥stico Manual:**
- Carregamento manual do checkpoint no primeiro batch (256 samples)
- Resultados: **243 predi√ß√µes RECT, 13 SPLIT, 0 AB**
- Accuracy: 43.75%
- **Confirmado:** Modelo carregado do checkpoint est√° colapsado

**Hip√≥teses Investigadas:**

1. ‚è© **Dropout/BatchNorm Mode:** Verificado - Script 004 usa `model.eval()` corretamente
2. ‚è© **Threshold de Classifica√ß√£o:** Verificado - Script 009 usa `argmax` padr√£o (sem threshold)
3. ‚è© **Dataset Diferente:** Verificado - Scripts 004 e 009 usam mesmos samples (valida√ß√£o v6)
4. ‚è© **Checkpoint Structure:** Verificado - `model_state_dict` tem 135 layers (backbone + head)
5. ‚è© **BatchNorm Running Stats:** Analisado - ResNet usa `track_running_stats=True`, mas em `eval()` n√£o atualiza

**Compara√ß√£o com History Original:**

Treinamento original Stage 2 (`logs/v6_experiments/stage2/stage2_history.pt`):
- √âpoca 1: Val Acc=48.76%, F1 macro=46.51%
- Per-class F1: SPLIT **40.75%**, RECT **60.66%**, AB **38.13%** ‚úÖ

**Conclus√£o:** Checkpoint salvo NO NOSSO treinamento est√° **incorreto/corrompido**.

### 5.4 Causa Raiz Identificada

**Hip√≥tese Principal:** 
Checkpoint foi salvo AP√ìS validation loop, mas `model.state_dict()` capturou estado interno **inconsistente** (possivelmente devido a timing de BatchNorm running statistics ou outra opera√ß√£o ass√≠ncrona no PyTorch).

**Evid√™ncias:**
1. M√©tricas computadas durante validation: F1 AB=41.73% ‚úÖ
2. Checkpoint salvo imediatamente ap√≥s validation: F1 AB=0.00% ‚ùå
3. Mesmo c√≥digo (`model.eval()`, mesmo dataloader, mesma loss)
4. Delta **-22.62pp F1** √© estatisticamente imposs√≠vel por vari√¢ncia aleat√≥ria

**Alternativas Investigadas (mas improv√°veis):**
- Bug no `torch.save/load`: Descartado (checkpoint structure correta)
- Seed randomness: Descartado (`model.eval()` desabilita dropout)
- Hardware error: Descartado (teste reproduzido 2x)

---

## 6. Conclus√£o do Experimento

### ‚ùå **EXP 10A FALHOU**

**Objetivo:** Recuperar modelo Stage 2 frozen (√©poca 1) funcional.

**Resultado:** 
- ‚úÖ Treinamento bem-sucedido (F1=48.52% durante training)
- ‚ùå Checkpoint n√£o pode ser carregado de forma confi√°vel (F1 degrada para 25.90%)
- ‚ùå Modelo recuperado n√£o √© utiliz√°vel para pipeline (AB completamente colapsado)

**Implica√ß√£o:** N√£o conseguimos resolver o bloqueio de Exp 10B/10C/10D.

---

## 7. Li√ß√µes Aprendidas e An√°lise Cr√≠tica

### 7.1 Descobertas Importantes

**1. Stage 1 Backbone √© ESSENCIAL para Stage 2:**
- Sem backbone Stage 1: F1=8.99% ‚ùå
- Com backbone Stage 1: F1=48.52% ‚úÖ
- **Ganho:** +39.53pp F1
- **Conclus√£o:** ImageNet-only pretraining √© **insuficiente** para particionar AV1

**2. Checkpoint Save/Load tem Bug N√£o-Determin√≠stico:**
- Problema persiste mesmo com c√≥digo correto
- Sugere issue no PyTorch ou timing de opera√ß√µes ass√≠ncronas
- **Necessidade:** Implementar valida√ß√£o de checkpoint **imediatamente** ap√≥s save

### 7.2 Erro de Design do Experimento

**Falha Metodol√≥gica:**
- Assumimos que `torch.save(model.state_dict())` ap√≥s `validate_epoch()` seria confi√°vel
- N√£o implementamos **checkpoint validation** (re-carregar e re-validar antes de confiar)

**Protocolo Corrigido (Futuro):**
```python
# Salvar checkpoint
torch.save({'model_state_dict': model.state_dict(), ...}, path)

# VALIDAR IMEDIATAMENTE
model_test = load_model(path)
quick_val_metrics = validate_epoch(model_test, val_loader_small, ...)
assert abs(quick_val_metrics['f1'] - original_f1) < 1.0, "Checkpoint corrupted!"
```

---

## 8. Pr√≥ximos Passos Alternativos

### Exp 10A est√° MORTO. Precisamos de estrat√©gia alternativa.

### Op√ß√£o 1: Re-treinar Stage 2 Frozen com Checkpoint Validation (‚è≥ Baixa Prioridade)

**Esfor√ßo:** M√©dio (implementar valida√ß√£o, retreinar)  
**Risco:** M√©dio (bug pode ser fundamental no PyTorch)  
**Impacto:** M√©dio (desbloqueia 10B/10C/10D)

### Op√ß√£o 2: Aceitar Stage 2 Colapsado e Compensar no Stage 3 (Exp 11A - Adapters) (üî¥ ALTA PRIORIDADE)

**Hip√≥tese:** Se Stage 3 for suficientemente robusto (com Adapters ou meta-learning), pode compensar Stage 2 ruim.

**Fundamenta√ß√£o:**
- Rebuffi et al. (2017): Residual Adapters permitem task-specific adaptation
- Finn et al. (2017): MAML permite fast adaptation com poucas amostras
- **Vantagem:** Contorna completamente problema do Stage 2

### Op√ß√£o 3: Arquitetura Flatten (9 classes diretas) (Exp 6) (üü° M√âDIA PRIORIDADE)

**Status:** J√° implementado (`docs_v6/06_arquitetura_flatten_9classes.md`)

**Resultado Hist√≥rico:**
- Accuracy: **42.39%** (inferior a 45.86% hier√°rquico)
- N√£o resolve problema fundamental

### Op√ß√£o 4: Oracle Experiment First (Exp 13) (üü¢ EXPLORAT√ìRIO)

**Hip√≥tese:** Testar upper bound do pipeline assumindo Stage 2 PERFEITO.

**Vantagem:** Descobre se vale a pena investir esfor√ßo em Stage 2 ou focar em Stage 3.

---

## 9. Recomenda√ß√£o Final

### üéØ **PRIORIDADE M√ÅXIMA: Experimento 11A (Adapter Layers)**

**Raz√£o:**
1. Contorna bloqueio do Stage 2 (n√£o depende de checkpoint funcional)
2. Fundamenta√ß√£o te√≥rica s√≥lida (Rebuffi et al., 2017)
3. Potencial de resolver negative transfer de forma arquitetural
4. Se falhar, ainda podemos tentar Op√ß√£o 4 (Oracle)

**Implementa√ß√£o:**
- Branch: `feat/exp11a-adapter-layers`
- Modificar `Stage2Model` para incluir Adapter modules
- Congelar backbone ResNet, treinar apenas adapters
- Esperado: F1=50-55% (melhor que 48.52%, sem catastrophic forgetting)

---

## 10. Refer√™ncias



## 6. Pr√≥ximos Passos

### Se Exp 10A for bem-sucedido (accuracy ‚â• 47%):

**Sequ√™ncia imediata:**
1. ‚úÖ Documentar resultados em `docs_v6/10_stage2_frozen_recovery.md`
2. ‚úÖ Atualizar `PROBLEMA_CRITICO_STAGE2.md` com resolu√ß√£o
3. ‚û°Ô∏è **Exp 10B:** Confusion-based noise injection (usar matriz do modelo frozen)
4. ‚û°Ô∏è **Exp 10D:** Ensemble AB real (3 modelos independentes)

### Se Exp 10A falhar (accuracy < 46%):

**Investiga√ß√£o adicional:**
1. ‚ö†Ô∏è Retreinar Stage 2 frozen com mais √©pocas (epochs=5, freeze_epochs=5)
2. ‚ö†Ô∏è Verificar se dataset v6 est√° correto (comparar com v5)
3. üîÑ Considerar **Exp 11A (Adapter Layers)** como solu√ß√£o alternativa

---

## 7. Impacto Esperado

### Desbloqueios

**Este experimento desbloqueia:**
- ‚úÖ Exp 10B (Confusion-based noise) - precisa de confusion matrix Stage 2 funcional
- ‚úÖ Exp 10C (Train-with-predictions) - precisa de Stage 2 funcional
- ‚úÖ Exp 10D (Ensemble AB) - precisa validar se Stage 2 frozen melhora AB
- ‚úÖ Exp 13B (Oracle experiment) - precisa de Stage 2 funcional para compara√ß√£o

**Total bloqueado:** 4 experimentos de alta/m√©dia prioridade

### Potencial de Ganho

| Cen√°rio | Accuracy Esperada | Ganho vs Baseline | Probabilidade |
|---------|------------------|-------------------|---------------|
| **Otimista** | 48.5% | +2.64pp | 30% |
| **Realista** | 47.5% | +1.64pp | 50% |
| **Conservador** | 46.5% | +0.64pp | 20% |

---

## 8. Riscos e Mitiga√ß√µes

### Risco 1: Modelo frozen pode ter degradado durante treinamento original

**Probabilidade:** Baixa (15%)  
**Mitiga√ß√£o:** Retreinar do zero (1 √©poca muito r√°pida, ~15s)

### Risco 2: F1=46.51% pode n√£o ser suficiente para pipeline

**Probabilidade:** M√©dia (40%)  
**Mitiga√ß√£o:** Prosseguir com Exp 10B (noise injection) para compensar Stage 2 fraco

### Risco 3: Exp 09 pode precisar ser refeito

**Probabilidade:** Alta (60%)  
**Impacto:** M√©dio - Exp 09 levou ~20 min, √© vi√°vel refazer  
**Mitiga√ß√£o:** Re-executar Exp 09 com Stage 2 frozen ap√≥s valida√ß√£o

---

## 9. Checklist de Execu√ß√£o

- [x] **Fase 1: Implementa√ß√£o**
  - [x] Modificar Script 004 (adicionar `--save-epoch-0`)
  - [x] Criar branch `feat/exp10a-recover-stage2-frozen`
  - [x] Executar treinamento (1 √©poca)

- [ ] **Fase 2: Valida√ß√£o Standalone**
  - [ ] Verificar checkpoint salvo (`stage2_model_epoch0_frozen.pt`)
  - [ ] Executar Script 009 (confusion matrix)
  - [ ] Verificar F1 ‚â• 46% e Acc ‚â• 48%

- [ ] **Fase 3: Valida√ß√£o Pipeline**
  - [ ] Executar Script 008 (pipeline completo)
  - [ ] Comparar com baseline Exp 09 (45.86%)
  - [ ] Verificar se classes HORZ_A/VERT_A recuperaram (F1 > 0%)

- [ ] **Fase 4: Documenta√ß√£o**
  - [ ] Criar `docs_v6/10_stage2_frozen_recovery.md`
  - [ ] Atualizar `PROBLEMA_CRITICO_STAGE2.md`
  - [ ] Atualizar `PLANO_v6_Out.md`
  - [ ] Commit e push das mudan√ßas

- [ ] **Fase 5: Decis√£o**
  - [ ] Se sucesso (‚â•47%): Prosseguir Exp 10B
  - [ ] Se falha (<46%): Investigar ou Exp 11A

---

## 10. Refer√™ncias

1. Kornblith et al. (2019) - "Do Better ImageNet Models Transfer Better?" - Frozen features > fine-tuning
2. Yosinski et al. (2014) - "How transferable are features in deep neural networks?" - Negative transfer
3. Howard & Ruder (2018) - "Universal Language Model Fine-tuning" (ULMFiT) - Gradual unfreezing
4. **Rebuffi et al. (2017)** - **"Learning multiple visual domains with residual adapters"** - **Solu√ß√£o recomendada (Exp 11A)**
5. Finn et al. (2017) - "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks" - MAML
6. He et al. (2016) - "Deep Residual Learning for Image Recognition" - ResNet-18 architecture

---

## 11. Checklist de Execu√ß√£o (FINAL)

- [x] **Fase 1: Implementa√ß√£o**
  - [x] Modificar Script 004 (adicionar `--save-epoch-0`)
  - [x] Modificar Script 004 (adicionar `--stage1-model` loading)
  - [x] Criar branch `feat/exp10a-recover-stage2-frozen`
  - [x] Executar treinamento (1 √©poca) - **SUCESSO (F1=48.52%)**

- [x] **Fase 2: Valida√ß√£o Standalone**
  - [x] Verificar checkpoint salvo (`stage2_model_epoch1_frozen.pt`)
  - [x] Executar Script 009 (confusion matrix)
  - [x] ‚ùå **FALHOU:** F1=25.90% (esperado 48.52%), AB completamente colapsado

- [x] **Fase 3: Investiga√ß√£o do Bug**
  - [x] Comparar m√©tricas training vs inference
  - [x] Testar predi√ß√µes manuais (primeiro batch)
  - [x] Verificar BatchNorm configuration
  - [x] Comparar com history original
  - [x] **Conclus√£o:** Checkpoint corrupted/inconsistent

- [x] **Fase 4: Documenta√ß√£o**
  - [x] Atualizar `docs_v6/10_exp10a_stage2_frozen_recovery.md` com resultados negativos
  - [x] Identificar causa raiz (checkpoint save timing issue)
  - [x] Propor solu√ß√µes alternativas (Exp 11A, Exp 13)
  - [x] Commit e push das mudan√ßas

- [ ] **Fase 5: Pr√≥ximos Passos**
  - [ ] ‚ùå Pipeline evaluation CANCELADO (checkpoint n√£o confi√°vel)
  - [ ] ‚û°Ô∏è **RECOMENDA√á√ÉO:** Implementar Exp 11A (Adapter Layers)
  - [ ] ‚è≥ Considerar: Re-treinar com checkpoint validation

---

## 12. Status Final

**Data de Conclus√£o:** 14 de outubro de 2025  
**Resultado:** ‚ùå **EXPERIMENTO FALHOU**  

**Problema:** Checkpoint save/load inconsistency - modelo funciona durante training (F1=48.52%) mas degrada ap√≥s reload (F1=25.90%).

**Bloqueios N√ÉO Resolvidos:**
- ‚ùå Exp 10B (Confusion-based noise) - precisa Stage 2 funcional
- ‚ùå Exp 10C (Train-with-predictions) - precisa Stage 2 funcional
- ‚ùå Exp 10D (Ensemble AB) - precisa Stage 2 funcional
- ‚ùå Exp 13B (Oracle experiment) - precisa Stage 2 funcional

**Pr√≥xima A√ß√£o Recomendada:**  
‚û°Ô∏è **Implementar Experimento 11A (Adapter Layers)** - contorna completamente problema do Stage 2 frozen

**Artifacts Gerados:**
- `pesquisa_v6/logs/v6_experiments/stage2_frozen_recovery_v2/stage2_model_epoch1_frozen.pt` - ‚ùå N√ÉO UTILIZ√ÅVEL
- `pesquisa_v6/logs/v6_experiments/stage2_frozen_recovery_v2/confusion_matrix.json` - Documenta colapso
- `pesquisa_v6/scripts/009b_debug_stage2_checkpoint.py` - Script diagn√≥stico (n√£o finalizado)

**Li√ß√µes para Tese:**
1. Transfer learning de Stage 1‚ÜíStage 2 aumenta F1 em +39.53pp (essencial)
2. Checkpoint validation IMEDIATA √© necess√°ria (descobrimos bug metodol√≥gico)
3. Hierarchical pipelines t√™m fragilidade em checkpoints intermedi√°rios
4. Adapters (Exp 11A) s√£o arquiteturalmente mais robustos que fine-tuning

---

**Branch:** `feat/exp10a-recover-stage2-frozen` (manter para hist√≥rico, N√ÉO merge)  
**Documento Atualizado:** 14 de outubro de 2025, 15:47 BRT
