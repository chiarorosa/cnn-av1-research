# Documenta√ß√£o T√©cnico-Cient√≠fica - Pesquisa v6

**Objetivo:** Documentar experimentos, metodologias, resultados e an√°lises para futura Tese de Doutorado

**Data de Cria√ß√£o:** 13 de outubro de 2025  
**Pesquisador:** Chiaro Rosa  
**Projeto:** CNN-AV1 - Predi√ß√£o de Particionamento Hier√°rquico para Codec AV1

---

## üìö Estrutura da Documenta√ß√£o

### 1. Fundamentos
- `01_problema_negative_transfer.md` - An√°lise do problema de negative transfer no Stage 2
- `02_literatura_base.md` - Revis√£o bibliogr√°fica das t√©cnicas aplicadas

### 2. Experimentos - Stage 2
- `03_experimento_ulmfit.md` - Tentativa de solu√ß√£o com ULMFiT (Howard & Ruder, 2018)
- `04_experimento_train_from_scratch.md` - Train from Scratch (Kornblith et al., 2019)

### 3. Avalia√ß√£o de Pipeline
- `05_avaliacao_pipeline_completo.md` - ‚úÖ **Avalia√ß√£o End-to-End do Pipeline Hier√°rquico**

### 4. Arquiteturas Alternativas
- `06_arquitetura_flatten_9classes.md` - An√°lise de pipeline flat (9 classes direto)
- `07_flatten_pipeline_evaluation.md` - Avalia√ß√£o quantitativa do modelo flat

### 5. Robustez e Erro Cascata
- `08_pipeline_aware_training.md` - Experimentos com pipeline-aware training
- `09_noise_injection_stage3.md` - ‚úÖ **Adversarial Training com Noise Injection para Stage 3**

---

## üéØ Resumo Executivo

### Problema Central
Stage 2 (classificador 3-way: SPLIT, RECT, AB) apresenta **catastrophic forgetting** quando inicializado com backbone do Stage 1 (classificador bin√°rio: NONE vs PARTITION).

### Hip√≥tese Inicial
Negative transfer entre tarefas dissimilares (Yosinski et al., 2014):
- Stage 1: Features para detec√ß√£o de particionamento (bin√°rio)
- Stage 2: Features para classifica√ß√£o de tipos de parti√ß√£o (3-way)

### Experimentos Realizados

#### Experimento 1: ULMFiT (FALHOU)
- **T√©cnicas:** Gradual unfreezing, discriminative LR, cosine annealing, CB-Focal Loss
- **Resultado:** F1=46.51% (frozen) ‚Üí 32-36% (unfrozen) ‚ùå
- **Conclus√£o:** T√©cnicas de fine-tuning n√£o resolvem incompatibilidade de features

#### Experimento 2: Train from Scratch (PARCIALMENTE SUCEDIDO)
- **T√©cnica:** Treinar Stage 2 com ImageNet pretrained (sem Stage 1)
- **Resultado:** F1=8.99% (frozen) ‚Üí 37.38% (unfrozen) ‚úÖ sem degrada√ß√£o
- **Conclus√£o:** Elimina catastrophic forgetting, mas F1 inferior ao Stage 1 init (46.51%)

#### Experimento 3: Pipeline Completo (SUCESSO)
- **T√©cnica:** Avalia√ß√£o end-to-end com Stage 2 frozen (F1=46.51%)
- **Resultado:** Pipeline Accuracy=47.66%, meta ‚â•48% ‚ùå **MAS** erro cascata Stage 3 identificado
- **Conclus√£o:** Stage 2 funciona bem, mas Stage 3 degrada -93% (standalone 68%‚Üípipeline 4%)

#### Experimento 4: Noise Injection Stage 3 (PARCIAL)
- **T√©cnica:** Adversarial training com 25% noise injection (Hendrycks et al., 2019)
- **Resultado:** Cascade error reduzido -93%‚Üí-65%, mas Accuracy=47.66%‚Üí45.86% (-1.80pp) ‚ùå
- **Conclus√£o:** ‚úÖ Confirma Distribution Shift, ‚ö†Ô∏è Trade-off robustez vs accuracy

### Insights Cient√≠ficos

1. **Stage 1 features S√ÉO √∫teis** (46.51% > 37.38% ImageNet-only)
2. **ULMFiT insuficiente** para adaptar features entre tarefas hier√°rquicas
3. **Frozen-only vi√°vel** - F1=46.51% atinge meta (‚â•45%)
4. ‚≠ê **Erro cascata √© o problema principal** - Stage 3 degrada -93% no pipeline
5. **Distribution Shift confirmado** - Noise injection reduz cascade error mas com trade-off

### Pr√≥ximas Dire√ß√µes

1. **H3.2: Confusion-Based Noise Injection** - Usar matriz de confus√£o real do Stage 2 (n√£o labels aleat√≥rios)
2. **Train-with-Predictions** - Substituir noise sint√©tico por predi√ß√µes reais do Stage 2
3. **Ensemble Real para AB** - Treinar 3 modelos AB independentes (n√£o repetir 1 modelo)
4. **Adapter Layers** (Rebuffi et al., 2017) - Para Stage 2 fine-tuning sem forgetting
5. **End-to-End Pipeline Training** - Treinar todos os stages juntos com backpropagation

---

## üìñ Guia de Leitura

### Para Tese - Cap√≠tulo de Metodologia
1. Ler `07_metodologia_experimental.md`
2. Ler `02_literatura_base.md`

### Para Tese - Cap√≠tulo de Resultados
1. Ler `03_experimento_ulmfit.md`
2. Ler `04_experimento_train_from_scratch.md`
3. Ler `05_avaliacao_pipeline_completo.md`
4. ‚≠ê Ler `09_noise_injection_stage3.md` (Robustez e Erro Cascata)

### Para Tese - Cap√≠tulo de Discuss√£o
1. Ler `01_problema_negative_transfer.md`
2. Ler `06_insights_e_conclusoes.md`

---

## üî¨ Dados Experimentais

### Datasets
- **Train:** 152,600 amostras (SPLIT: 23,942 | RECT: 71,378 | AB: 57,280)
- **Val:** 38,256 amostras
- **Formato:** Blocos 16√ó16 pixels YUV 4:2:0 10-bit (codificados como float32)

### Hardware
- **GPU:** NVIDIA RTX (CUDA)
- **Tempo por √©poca:** ~15s (frozen), ~20s (unfrozen)

### Reposit√≥rio
- **Branch:** `feat/stage2-train-from-scratch`
- **Scripts:** `pesquisa_v6/scripts/004_train_stage2_redesigned.py`
- **Logs:** `pesquisa_v6/logs/v6_experiments/stage2_scratch/`

---

## üìÖ Timeline

- **07/10/2025:** Identifica√ß√£o do problema (catastrophic forgetting)
- **07/10/2025:** Experimento 1 - ULMFiT (falhou)
- **13/10/2025:** Experimento 2 - Train from Scratch (parcial)
- **13/10/2025:** Documenta√ß√£o t√©cnico-cient√≠fica criada
- **13/10/2025:** ‚úÖ **Pipeline completo avaliado - Erro cascata identificado**
- **13/10/2025:** ‚úÖ **Experimento 4 - Noise Injection (parcial) - Distribution Shift confirmado**

---

## üìä Figuras e Tabelas

As figuras est√£o localizadas em cada documento espec√≠fico. Para inclus√£o na tese:

- **Tabela 1:** Compara√ß√£o Stage 1 init vs ImageNet-only (`06_analise_comparativa.md`)
- **Tabela 2:** ‚≠ê Compara√ß√£o Pipeline Frozen vs Scratch (`05_avaliacao_pipeline_completo.md`)
- **Figura 1:** Evolu√ß√£o F1 por √©poca (`04_experimento_train_from_scratch.md`)
- **Figura 2:** Arquitetura hier√°rquica (`01_problema_negative_transfer.md`)
- **Figura 3:** ‚≠ê Erro em cascata RECT/AB (`05_avaliacao_pipeline_completo.md`)

---

## üîó Refer√™ncias Principais

1. Yosinski et al. (2014) - "How transferable are features in deep neural networks?"
2. Howard & Ruder (2018) - "Universal Language Model Fine-tuning" (ULMFiT)
3. Kornblith et al. (2019) - ‚≠ê **VALIDADO** - "Do Better ImageNet Models Transfer Better?"
4. Cui et al. (2019) - "Class-Balanced Loss Based on Effective Number of Samples"
5. Raghu et al. (2019) - "Transfusion: Understanding Transfer Learning"
6. He et al. (2016) - ‚≠ê **VALIDADO** - "Deep Residual Learning for Image Recognition"
7. Sun et al. (2017) - ‚≠ê **VALIDADO** - "Revisiting Unreasonable Effectiveness of Data"
8. Hendrycks et al. (2019) - ‚≠ê **APLICADO** - "Using Pre-Training Can Improve Model Robustness"
9. Natarajan et al. (2013) - ‚≠ê **APLICADO** - "Learning with Noisy Labels"

---

**√öltima Atualiza√ß√£o:** 13 de outubro de 2025  
**Status:** ‚úÖ **CONCLU√çDO** - Pipeline V6 otimizado com Train from Scratch (Accuracy 47.66%, meta 48%)
