# Experimento 2: Train from Scratch (ImageNet-Only Pretrained)

**Data:** 13 de outubro de 2025  
**Dura√ß√£o:** ~1.5 horas de treinamento  
**Status:** ‚ö†Ô∏è PARCIALMENTE SUCEDIDO  
**Relev√¢ncia para Tese:** Cap√≠tulo de Resultados / An√°lise de Solu√ß√µes Alternativas

---

## 1. Motiva√ß√£o

Ap√≥s falha do Experimento 1 (ULMFiT), observamos que:
1. Stage 1 features **s√£o √∫teis inicialmente** (F1=46.51% frozen)
2. Fine-tuning **sempre degrada** essas features (F1=34%)
3. Negative transfer parece **insuper√°vel** com t√©cnicas de fine-tuning

**Nova Hip√≥tese (baseada em Kornblith et al., 2019):**
> "Se Stage 1 features causam negative transfer, talvez features GEN√âRICAS do ImageNet sejam superiores ap√≥s fine-tuning completo."

**Objetivo do Experimento:**
> "Treinar Stage 2 **sem** inicializa√ß√£o do Stage 1, usando apenas ImageNet ResNet-18 pretrained. Verificar se elimina catastrophic forgetting e permite unfreezing bem-sucedido."

---

## 2. Fundamenta√ß√£o Te√≥rica

### 2.1 Paper Base

**"Do Better ImageNet Models Transfer Better?"**  
Kornblith, S., Shlens, J., & Le, Q. V. (2019). *CVPR 2019*

**Insights Principais:**

1. **Transfer Learning n√£o √© sempre melhor:**
   - Nem sempre task-specific pretraining > ImageNet pretraining
   - Depende de: (a) similaridade de tasks, (b) quantidade de dados target

2. **ImageNet features s√£o surpreendentemente gerais:**
   - Features de baixo n√≠vel (edges, textures) √∫teis em muitos dom√≠nios
   - Features de alto n√≠vel (object parts) podem ser prejudiciais se tasks s√£o diferentes

3. **Fine-tuning completo pode ser necess√°rio:**
   - Se source e target s√£o diferentes, fine-tuning precisa re-aprender features finais
   - Frozen features boas apenas se tasks s√£o muito similares

**Aplica√ß√£o ao Nosso Caso:**

| Aspecto | Stage 1 ‚Üí Stage 2 | ImageNet ‚Üí Stage 2 |
|---------|-------------------|-------------------|
| **Similaridade Source-Target** | Baixa (binary vs 3-way) | M√©dia (objetos vs blocos) |
| **Feature Bias** | Binary detection (espec√≠fico) | Object recognition (gen√©rico) |
| **Fine-tuning vi√°vel?** | ‚ùå (causa negative transfer) | ‚úÖ (sem vi√©s task-specific) |

**Previs√£o:**
- Baseline (frozen) ser√° **PIOR** (ImageNet n√£o conhece video blocks)
- Mas ap√≥s unfreezing, deve **MELHORAR** (sem catastrophic forgetting)
- F1 final pode superar Stage 1 init se convergir bem

### 2.2 Compara√ß√£o com Raghu et al. (2019) - "Transfusion"

**Paper:** "Transfusion: Understanding Transfer Learning for Medical Imaging"

**Insight Relevante:**
- Medical imaging: ImageNet pretrained > domain-specific pretrained
- Raz√£o: Domain-specific features s√£o **muito especializadas**
- ImageNet features s√£o **gen√©ricas o suficiente** para adaptar

**Analogia com Nosso Caso:**
- Stage 1 binary = "domain-specific" (detec√ß√£o de parti√ß√£o)
- ImageNet = "gen√©rico" (detec√ß√£o de objetos/bordas)
- Stage 2 3-way = target task (classifica√ß√£o de tipos)

**Conclus√£o:** ImageNet pode ser melhor base para Stage 2 que Stage 1

---

## 3. Protocolo Experimental

### 3.1 Modifica√ß√µes vs ULMFiT

**√öNICA mudan√ßa no c√≥digo:**
```python
# ANTES (ULMFiT - linha ~283):
checkpoint_stage1 = torch.load(stage1_model_path, ...)
model.backbone.load_state_dict(checkpoint_stage1['model_state_dict'])

# DEPOIS (Train from Scratch - linhas 295-308):
# ‚ö†Ô∏è  NOT loading Stage 1 backbone due to Negative Transfer
# Reason: Stage 1 (binary) features are incompatible with Stage 2 (3-way)
# References: Yosinski et al., 2014 + Kornblith et al., 2019
# Solution: Use only ImageNet pretrained ResNet-18 (pretrained=True)
print(f"  üìö Using ImageNet-only pretrained ResNet-18")
print(f"  üî¨ Strategy: Train from scratch to avoid negative transfer")
```

**Mantido de ULMFiT:**
- Freeze epochs: 8
- Discriminative LR: head=5e-4, backbone=1e-6
- Cosine annealing scheduler
- CB-Focal Loss (gamma=2.0, beta=0.9999)
- Todas as outras configura√ß√µes id√™nticas

### 3.2 Configura√ß√£o Completa

```yaml
Epochs: 30
Freeze epochs: 8
Batch size: 128
LR head: 5e-4
LR backbone: 1e-6
Weight decay: 1e-4
Focal gamma: 2.0
CB beta: 0.9999
Scheduler: CosineAnnealingLR (T_max=22)
Device: CUDA
Seed: 42

# CR√çTICO: Inicializa√ß√£o do backbone
Backbone init: ImageNet ResNet-18 pretrained  # ‚Üê √öNICO CHANGE
Head init: Random (Xavier uniform)
```

---

## 4. Resultados

### 4.1 Fase FROZEN (√âpocas 1-8) - COLAPSO INICIAL

| √âpoca | Macro F1 | SPLIT F1 | RECT F1 | AB F1 | Observa√ß√£o |
|-------|----------|----------|---------|-------|------------|
| 1 | **8.99%** | 26.97% | 0.00% | 0.00% | ‚ùå Collapse! |
| 2 | 8.99% | 26.97% | 0.00% | 0.00% | Estagnado |
| 3 | 8.99% | 26.97% | 0.00% | 0.00% | Estagnado |
| 4 | 8.99% | 26.97% | 0.00% | 0.00% | Estagnado |
| 5 | 8.99% | 26.97% | 0.00% | 0.00% | Estagnado |
| 6 | 8.99% | 26.97% | 0.00% | 0.00% | Estagnado |
| 7 | 8.99% | 26.97% | 0.00% | 0.00% | Estagnado |
| 8 | 8.99% | 26.97% | 0.00% | 0.00% | Estagnado |

**Accuracy:** 15.58% (todas as √©pocas)

**üîç An√°lise do Colapso:**

1. **RECT e AB colapsaram completamente (F1=0%)**
   - Modelo prev√™ **TUDO como SPLIT**
   - Accuracy 15.58% ‚âà propor√ß√£o de SPLIT no dataset (15.7%)

2. **Head n√£o consegue aprender sobre features frozen do ImageNet**
   - ImageNet features (objetos, animais, cenas) s√£o **muito diferentes** de video blocks
   - Head tenta mapear, mas features s√£o incompat√≠veis
   - Colapsa para classe mais "confusa" (SPLIT, a minorit√°ria)

3. **Compara√ß√£o com ULMFiT (Stage 1 init):**
   - ULMFiT frozen: F1=46.51% ‚úÖ
   - ImageNet frozen: F1=8.99% ‚ùå
   - **Diferen√ßa: -80.7%** (Stage 1 features S√ÉO √∫teis!)

**Conclus√£o Fase FROZEN:**
> "ImageNet features gen√©ricas N√ÉO s√£o suficientes para Stage 2. Head precisa de backbone adaptado para video blocks."

### 4.2 Fase UNFROZEN (√âpocas 9-30) - RECUPERA√á√ÉO DRAM√ÅTICA

#### √âpoca 9: Unfreezing (Ainda Colapsado)

```
üîì Unfreezing backbone with Discriminative LR
   Head LR: 5.00e-04
   Backbone LR: 1.00e-06 (500x smaller)
```

| √âpoca | Macro F1 | SPLIT F1 | RECT F1 | AB F1 | Observa√ß√£o |
|-------|----------|----------|---------|-------|------------|
| 9 | 8.99% | 26.97% | 0.00% | 0.00% | Ainda colapsado |

#### √âpoca 10: BREAKTHROUGH! üéâ

| √âpoca | Macro F1 | SPLIT F1 | RECT F1 | AB F1 | Observa√ß√£o |
|-------|----------|----------|---------|-------|------------|
| 10 | **32.90%** | 34.78% | 63.92% | 0.00% | ‚úÖ **SALTO +266%!** |

**An√°lise:**
- F1 salta de 8.99% ‚Üí 32.90% (+23.91pp)
- RECT aprende: 0% ‚Üí 63.92%
- SPLIT estabiliza: 26.97% ‚Üí 34.78%
- AB ainda colapsado (0%)
- **Backbone come√ßou a adaptar para video blocks!**

#### √âpocas 11-17: Crescimento Gradual

| √âpoca | Macro F1 | SPLIT F1 | RECT F1 | AB F1 | Milestone |
|-------|----------|----------|---------|-------|-----------|
| 11 | 33.33% | 35.31% | 64.68% | 0.00% | +1.3% |
| 12 | 33.74% | 35.90% | 65.32% | 0.00% | ‚úÖ Best at√© aqui |
| 13 | 33.17% | 35.31% | 64.21% | 0.00% | Leve queda |
| 14 | 33.21% | 35.40% | 64.19% | **0.04%** | üéØ AB come√ßa! |
| 15 | 34.12% | 36.65% | 65.73% | 0.00% | ‚úÖ New best |
| 16 | 34.02% | 36.23% | 64.98% | **0.83%** | AB crescendo |
| 17 | **35.11%** | 36.64% | 65.21% | **3.47%** | ‚úÖ **BREAKTHROUGH AB!** |

**An√°lise √âpoca 17:**
- **AB finalmente aprendeu!** (0% ‚Üí 3.47%)
- SPLIT e RECT est√°veis e bons
- F1 geral subiu para 35.11%

#### √âpocas 18-26: AB Acelerando

| √âpoca | Macro F1 | SPLIT F1 | RECT F1 | AB F1 | Observa√ß√£o |
|-------|----------|----------|---------|-------|------------|
| 18 | 34.84% | 36.38% | 65.09% | 3.06% | AB oscilando |
| 19 | 34.35% | 36.45% | 65.21% | 1.38% | AB regride |
| 20 | 33.64% | 35.97% | 64.23% | 0.71% | AB quase colapsa |
| 21 | 34.27% | 36.34% | 64.90% | 1.56% | Recupera |
| 22 | 34.75% | 37.61% | 66.38% | 0.26% | SPLIT melhora |
| 23 | 36.07% | 36.88% | 65.59% | **5.75%** | ‚úÖ **AB salto!** |
| 24 | 34.96% | 37.32% | 66.00% | 1.56% | AB regride |
| 25 | 34.34% | 35.71% | 63.57% | 3.73% | Todos oscilam |
| 26 | **37.38%** | 36.31% | 64.88% | **10.94%** | ‚úÖ **BEST OVERALL** |

**An√°lise √âpoca 26 (BEST MODEL):**
- Macro F1: **37.38%** (record)
- SPLIT: 36.31% (est√°vel)
- RECT: 64.88% (excelente)
- AB: **10.94%** (finalmente aprendendo!)

#### √âpocas 27-30: Overfitting

| √âpoca | Macro F1 | SPLIT F1 | RECT F1 | AB F1 | Observa√ß√£o |
|-------|----------|----------|---------|-------|------------|
| 27 | 34.50% | 37.10% | 65.43% | 0.96% | AB colapsa |
| 28 | 35.47% | 37.32% | 65.85% | 3.24% | Recupera |
| 29 | 34.77% | 37.59% | 66.12% | 0.59% | AB oscila |
| 30 | 35.04% | 37.84% | 66.26% | 1.02% | Final |

**Modelo Final (√âpoca 30):**
- Macro F1: 35.04%
- Best foi √©poca 26: 37.38%
- **Conclus√£o:** Overfitting ap√≥s √©poca 26

### 4.3 An√°lise de Loss

**Training Loss:**
```
√âpoca 1-8 (frozen):   0.4878-0.4881 (est√°vel, n√£o aprende)
√âpoca 9 (unfreeze):   0.4879 (sem mudan√ßa)
√âpoca 10-30:          0.4607-0.4725 (decrescendo consistentemente)
```

**Validation Loss:**
```
√âpoca 1-8 (frozen):   0.4850-0.4889 (est√°vel)
√âpoca 9 (unfreeze):   0.4855 (sem mudan√ßa)
√âpoca 10-26:          0.4468-0.4747 (decrescendo)
√âpoca 27-30:          0.4471-0.4668 (subindo levemente - overfitting)
```

**‚úÖ Observa√ß√£o Positiva:**
- Training e validation losses **convergem juntos**
- Loss correlaciona com F1 (ao contr√°rio de ULMFiT)
- Sem overfitting at√© √©poca 26

---

## 5. An√°lise Comparativa: ULMFiT vs Train from Scratch

### 5.1 Compara√ß√£o Quantitativa

| M√©trica | ULMFiT (Stage 1 init) | Train from Scratch (ImageNet) | Diferen√ßa |
|---------|----------------------|-------------------------------|-----------|
| **Frozen Phase F1** | 46.51% (√©poca 1) | 8.99% (todas) | **-80.7%** ‚ùå |
| **Best Unfrozen F1** | 34.12% (oscilando) | 37.38% (√©poca 26) | **+9.5%** ‚úÖ |
| **SPLIT (best)** | 40.75% (frozen) | 37.84% (√©poca 30) | **-7.1%** ‚ùå |
| **RECT (best)** | 66.48% (frozen) | 66.38% (√©poca 22) | **-0.2%** ‚âà |
| **AB (best)** | 38.13% (frozen) | 10.94% (√©poca 26) | **-71.3%** ‚ùå |
| **Catastrophic Forgetting?** | **SIM** (46‚Üí34%) | **N√ÉO** (9‚Üí37%) | ‚úÖ RESOLVIDO |

### 5.2 An√°lise Per-Class

#### SPLIT (Classe Minorit√°ria, 15.7%)
**ULMFiT:**
- Frozen: 40.75% ‚Üí Unfrozen: 22.45% (**-44.9%** degrada√ß√£o)

**Train from Scratch:**
- Frozen: 26.97% ‚Üí Unfrozen: 37.84% (**+40.3%** melhora)

**Conclus√£o:** Train from Scratch **permite** SPLIT melhorar, ULMFiT **destr√≥i** SPLIT.

#### RECT (Classe Majorit√°ria, 46.8%)
**ULMFiT:**
- Frozen: 66.48% ‚Üí Unfrozen: 51.23% (**-23.0%** degrada√ß√£o)

**Train from Scratch:**
- Frozen: 0.00% ‚Üí Unfrozen: 66.38% (**+‚àû** melhora)

**Conclus√£o:** Ambas atingem ~66% RECT no melhor caso, mas Train from Scratch demora mais para convergir.

#### AB (Classe Intermedi√°ria, 37.5%)
**ULMFiT:**
- Frozen: 38.13% ‚Üí Unfrozen: 28.68% (**-24.8%** degrada√ß√£o)

**Train from Scratch:**
- Frozen: 0.00% ‚Üí Unfrozen: 10.94% (**+‚àû** melhora, mas baixo)

**Conclus√£o:** AB √© o gargalo do Train from Scratch. Precisa de **muito mais √©pocas** para convergir.

### 5.3 Evolu√ß√£o Temporal

**ULMFiT:**
```
√âpoca 1:  F1=46.51% ‚úÖ Excelente start
√âpoca 9:  F1=34.39% ‚ùå Catastrophic drop
√âpoca 30: F1=34.12% ‚ö†Ô∏è Estagnado em patamar baixo
```

**Train from Scratch:**
```
√âpoca 1:  F1=8.99%  ‚ùå Colapso inicial
√âpoca 10: F1=32.90% üöÄ Breakthrough
√âpoca 26: F1=37.38% ‚úÖ Best model
√âpoca 30: F1=35.04% ‚ö†Ô∏è Overfitting leve
```

**Padr√£o:**
- ULMFiT: Peak early, degrade forever
- Train from Scratch: Collapse early, improve steadily

---

## 6. Interpreta√ß√£o dos Resultados

### 6.1 Por Que Train from Scratch Funciona?

#### ‚úÖ Elimina Negative Transfer
**Mecanismo:**
- ImageNet features s√£o **gen√©ricas** (edges, textures)
- N√£o t√™m vi√©s para binary detection (como Stage 1)
- Quando backbone √© unfrozen, pode **livremente adaptar** para 3-way task

**Evid√™ncia:**
- F1 melhora de 8.99% ‚Üí 37.38% (+315% crescimento!)
- Sem degrada√ß√£o ao unfreeze (ao contr√°rio de ULMFiT)

#### ‚úÖ Permite Fine-Tuning Completo
**Mecanismo:**
- Layers finais (layer4) re-aprendem features espec√≠ficas para partition types
- Layers iniciais (layer1-3) preservam features gen√©ricas (edges)
- Discriminative LR (1e-6 backbone) protege layers iniciais

**Evid√™ncia:**
- Training/val loss convergem juntos
- F1 correlaciona com loss (modelo aprende corretamente)

### 6.2 Por Que Train from Scratch √â Inferior a ULMFiT Frozen?

#### ‚ùå ImageNet Features S√£o "Demais Gen√©ricas"
**Problema:**
- ImageNet: Objetos cotidianos (cachorros, carros, pessoas)
- Stage 2: Video blocks 16√ó16 YUV (padr√µes de compress√£o)
- **Gap** muito grande entre dom√≠nios

**Evid√™ncia:**
- Fase frozen: F1=8.99% (collapse completo)
- Stage 1 frozen: F1=46.51% (5x melhor!)

**Conclus√£o:** Stage 1 features **s√£o √∫teis**, problema √© fine-tuning, n√£o as features em si.

#### ‚ùå AB Requer Mais Dados/√âpocas
**Problema:**
- AB (assim√©trico) √© mais complexo que SPLIT/RECT
- Train from Scratch precisa aprender AB **do zero**
- 30 √©pocas insuficientes (AB chegou apenas 10.94%)

**Compara√ß√£o:**
- ULMFiT frozen: AB=38.13% (Stage 1 j√° tinha features √∫teis)
- Train from Scratch: AB=10.94% (precisa aprender tudo)
- **Gap: -71.3%**

**Proje√ß√£o:** Com 50-100 √©pocas, AB poderia atingir ~25-30%

### 6.3 Trade-Off: Start vs Convergence

**ULMFiT (Stage 1 init):**
- ‚úÖ **Excellent start:** F1=46.51% (√©poca 1)
- ‚ùå **Poor convergence:** Degrada para 34%
- **Uso recomendado:** Frozen-only (√©poca 1)

**Train from Scratch (ImageNet):**
- ‚ùå **Poor start:** F1=8.99% (√©pocas 1-8)
- ‚úÖ **Good convergence:** Melhora para 37.38% (√©poca 26)
- **Uso recomendado:** Full training (26+ √©pocas)

**Conclus√£o:** Depende de disponibilidade de compute:
- **Budget limitado (1 √©poca):** ULMFiT frozen (46.51%)
- **Budget amplo (30+ √©pocas):** Train from Scratch (37.38%, mas crescendo)

---

## 7. Valida√ß√£o da Hip√≥tese Original

### 7.1 Hip√≥tese Testada

> "Treinar Stage 2 sem Stage 1 (ImageNet-only) elimina catastrophic forgetting e permite fine-tuning bem-sucedido."

### 7.2 Resultado

**Parte 1: Elimina catastrophic forgetting?**
‚úÖ **SIM, CONFIRMADO**
- F1 melhora de 8.99% ‚Üí 37.38% (+315%)
- Sem degrada√ß√£o ao unfreeze (ao contr√°rio de ULMFiT)

**Parte 2: Permite fine-tuning bem-sucedido?**
‚ö†Ô∏è **PARCIALMENTE**
- Fine-tuning funciona (F1 cresce consistentemente)
- Mas F1 final (37.38%) < ULMFiT frozen (46.51%)
- AB n√£o converge completamente (10.94% vs 38.13%)

### 7.3 Refinamento da Hip√≥tese

**Hip√≥tese Revisada:**
> "Train from Scratch elimina catastrophic forgetting, mas performance final depende de: (1) quantidade de √©pocas, (2) complexidade da classe (AB √© gargalo), (3) trade-off start vs convergence."

**Implica√ß√µes:**
1. **ULMFiT frozen** ainda √© melhor para meta de curto prazo (F1 ‚â• 45%)
2. **Train from Scratch** pode superar com mais √©pocas (50-100+)
3. **Hybrid approach** pode ser √≥timo (iniciar com Stage 1, mas adapters?)

---

## 8. Insights Cient√≠ficos para a Tese

### 8.1 Contribui√ß√£o 1: Confirma√ß√£o de Kornblith et al. (2019)

**Cita√ß√£o:**
> "Kornblith et al. (2019) mostraram que nem sempre task-specific pretraining √© superior a ImageNet pretraining. Nossos resultados confirmam: Stage 1 (task-specific) teve F1=46.51% frozen mas degradou para 34% ao fine-tuning. ImageNet (gen√©rico) teve F1=8.99% frozen mas melhorou para 37.38% ao fine-tuning. **Conclus√£o:** Task-specific features s√£o melhores inicialmente, mas **prejudicam adapta√ß√£o**."

### 8.2 Contribui√ß√£o 2: Caracteriza√ß√£o de AB como Classe "Hard"

**Observa√ß√£o:**
- SPLIT e RECT convergiram em ~15 √©pocas
- AB demorou 26 √©pocas e s√≥ atingiu 10.94%

**An√°lise:**
- AB (assim√©trico) requer features **muito espec√≠ficas**
- SPLIT (quad): Borda em cruz (simples)
- RECT (retangular): Borda √∫nica (simples)
- AB: Borda assim√©trica (complexa, requer spatial reasoning)

**Implica√ß√£o:** Arquiteturas futuras devem dar aten√ß√£o especial a AB (e.g., spatial attention, ensemble).

### 8.3 Contribui√ß√£o 3: Quantifica√ß√£o do Trade-Off

**Tabela para Tese:**

| Abordagem | Frozen F1 | Unfrozen F1 | Catastrophic Forgetting | Epochs to Converge |
|-----------|-----------|-------------|-------------------------|-------------------|
| **Stage 1 init** | 46.51% | 34.12% | **SIM** (-26.6%) | N/A (n√£o converge) |
| **ImageNet init** | 8.99% | 37.38% | **N√ÉO** (+315%) | ~26 |
| **Target** | - | ‚â• 45% | N√ÉO | < 30 |

**Conclus√£o para Tese:**
> "Identificamos trade-off fundamental entre performance inicial e capacidade de adapta√ß√£o. Task-specific features (Stage 1) fornecem forte baseline mas resistem a fine-tuning. Features gen√©ricas (ImageNet) t√™m baseline fraco mas permitem adapta√ß√£o. Para aplica√ß√µes que exigem fine-tuning iterativo, ImageNet pretrained pode ser prefer√≠vel apesar de baseline inferior."

---

## 9. Limita√ß√µes do Estudo

### 9.1 √âpocas Insuficientes para AB

**Problema:**
- AB atingiu apenas 10.94% em 30 √©pocas
- Tend√™ncia de crescimento sugere que precisa de 50-100 √©pocas

**Impacto:**
- F1 final (37.38%) √© subestimado
- Com mais √©pocas, poderia superar ULMFiT frozen (46.51%)

**Experimento Futuro:**
- Treinar 100 √©pocas e monitorar converg√™ncia de AB

### 9.2 Apenas ImageNet Testado

**Problema:**
- Testamos apenas ImageNet ResNet-18
- Outros pretraining podem ter resultados diferentes:
  - ResNet-50 (mais capacidade)
  - EfficientNet (mais eficiente)
  - Vision Transformer (attention-based)
  - CLIP (language-vision)

**Impacto:**
- Conclus√µes limitadas a ResNet-18
- Arquiteturas modernas podem ter melhor baseline frozen

### 9.3 √önico Dataset

**Problema:**
- Apenas UVG dataset testado
- Generaliza√ß√£o para outros v√≠deos (Netflix, YouTube, etc.) n√£o validada

**Impacto:**
- Resultados podem ser espec√≠ficos de UVG (720p, padr√µes espec√≠ficos)

---

## 10. Recomenda√ß√µes para Pr√≥ximos Passos

### 10.1 Op√ß√£o A: Usar ULMFiT Frozen (Recomendado para Curto Prazo)

**Estrat√©gia:**
- Treinar Stage 2 com Stage 1 init
- Salvar modelo da **√©poca 1** (F1=46.51%)
- **NUNCA** fazer unfreezing
- Usar no pipeline 008

**Vantagens:**
- ‚úÖ F1=46.51% > meta de 45%
- ‚úÖ Modelo pronto agora
- ‚úÖ Sem complexidade adicional

**Desvantagens:**
- ‚ùå N√£o permite fine-tuning futuro
- ‚ùå Limitado por features Stage 1

### 10.2 Op√ß√£o B: Treinar 100 √âpocas from Scratch

**Estrat√©gia:**
- Continuar treinamento de ImageNet-only por mais 70 √©pocas
- Monitorar AB convergence

**Vantagens:**
- ‚úÖ Pode superar 46.51% se AB convergir
- ‚úÖ Permite fine-tuning sem degrada√ß√£o

**Desvantagens:**
- ‚ùå Custo computacional: ~5h adicionais
- ‚ùå Risco de overfitting
- ‚ùå Incerteza (AB pode n√£o convergir)

### 10.3 Op√ß√£o C: Adapter Layers (Rebuffi et al., 2017)

**Estrat√©gia:**
- Manter Stage 1 backbone **frozen**
- Adicionar adapters trein√°veis entre layers
- Treinar apenas adapters + head

**Vantagens:**
- ‚úÖ Preserva Stage 1 features (F1=46.51% baseline)
- ‚úÖ Permite adapta√ß√£o (adapters aprendem deltas)
- ‚úÖ Usado com sucesso em NLP (LoRA, etc.)

**Desvantagens:**
- ‚ùå Complexidade implementa√ß√£o: 2-3 dias
- ‚ùå Hiperpar√¢metros novos (adapter dim, placement)

---

## 11. Artefatos e Reprodutibilidade

### 11.1 C√≥digo Modificado

**Diff vs ULMFiT:**
```diff
--- pesquisa_v6/scripts/004_train_stage2_redesigned_BACKUP.py
+++ pesquisa_v6/scripts/004_train_stage2_redesigned.py

@@ -1,5 +1,5 @@
 """
-Script 004: Train Stage 2 Redesigned
+Script 004: Train Stage 2 Redesigned (Train from Scratch)

@@ -283,12 +295,16 @@
     model = Stage2Model(pretrained=True).to(device)
     
-    # Load Stage 1 backbone if available
-    if Path(args.stage1_model).exists():
-        checkpoint = torch.load(args.stage1_model, ...)
-        model.backbone.load_state_dict(...)
-        print(f"  ‚úÖ Backbone initialized from Stage 1")
+    # ‚ö†Ô∏è  NOT loading Stage 1 backbone due to Negative Transfer
+    # Reason: Stage 1 (binary) features are incompatible with Stage 2 (3-way)
+    # References: Yosinski et al., 2014 + Kornblith et al., 2019
+    # Solution: Use only ImageNet pretrained ResNet-18 (pretrained=True)
+    print(f"  üìö Using ImageNet-only pretrained ResNet-18")
+    print(f"  üî¨ Strategy: Train from scratch to avoid negative transfer")
+    print(f"  üìÑ See: PLANO_v6_val2.md (Op√ß√£o 1)")
```

### 11.2 Comando de Execu√ß√£o

```bash
python3 pesquisa_v6/scripts/004_train_stage2_redesigned.py \
  --dataset-dir pesquisa_v6/v6_dataset/block_16 \
  --output-dir pesquisa_v6/logs/v6_experiments/stage2_scratch \
  --epochs 30 \
  --freeze-epochs 8 \
  --batch-size 128 \
  --lr 5e-4 \
  --lr-backbone 1e-6 \
  --device cuda \
  --seed 42
```

### 11.3 Checkpoints

**Localiza√ß√£o:**
```
pesquisa_v6/logs/v6_experiments/stage2_scratch/
‚îú‚îÄ‚îÄ stage2_model_best.pt      # √âpoca 26, F1=37.38%
‚îú‚îÄ‚îÄ stage2_model_final.pt     # √âpoca 30, F1=35.04%
‚îú‚îÄ‚îÄ stage2_history.pt
‚îî‚îÄ‚îÄ stage2_metrics.json
```

**Best Model:**
```json
{
  "epoch": 26,
  "macro_f1": 0.3738,
  "split_f1": 0.3631,
  "rect_f1": 0.6488,
  "ab_f1": 0.1094,
  "accuracy": 0.4722
}
```

---

## 12. Refer√™ncias

1. Kornblith, S., Shlens, J., & Le, Q. V. (2019). Do better imagenet models transfer better?. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 2661-2671).

2. Raghu, M., Zhang, C., Kleinberg, J., & Bengio, S. (2019). Transfusion: Understanding transfer learning for medical imaging. In *Advances in neural information processing systems* (pp. 3347-3357).

3. Yosinski, J., Clune, J., Bengio, Y., & Lipson, H. (2014). How transferable are features in deep neural networks?. In *Advances in neural information processing systems* (pp. 3320-3328).

4. He, K., Zhang, X., Ren, S., & Sun, J. (2019). Rethinking imagenet pre-training. In *Proceedings of the IEEE/CVF International Conference on Computer Vision* (pp. 4918-4927).

---

**√öltima Atualiza√ß√£o:** 13 de outubro de 2025  
**Status:** Experimento conclu√≠do - Hip√≥tese parcialmente confirmada (elimina CF, mas F1 < ULMFiT frozen)
