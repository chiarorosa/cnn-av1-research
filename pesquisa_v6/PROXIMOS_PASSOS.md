# Pr√≥ximos Passos - Pipeline V6 (Atualizado 13/10/2025 - 20:00)

**√öltima Atualiza√ß√£o:** 13/10/2025 20:00  
**Status:** üö® **PROBLEMA CR√çTICO IDENTIFICADO** - Stage 2 colapsado, Experimento 10 bloqueado  
**Respons√°vel:** @chiarorosa

---

## üö® PROBLEMA CR√çTICO: Stage 2 Model Colapsado

### Descoberta (13/10/2025 19:30)

Durante a implementa√ß√£o do Script 009 (an√°lise de confusion matrix), **descobriu-se que o modelo Stage 2 est√° completamente colapsado**:

**Modelo Best (stage2_model_best.pt):**
- Prediz **RECT (classe 1) para 100%** das amostras
- Accuracy: 46.44% (= preval√™ncia de RECT no dataset)
- F1 macro: 0.21 (SPLIT=0.0, RECT=0.63, AB=0.0)

**Modelo Final (stage2_model_final.pt):**
- Prediz **SPLIT (classe 0) para 99.99%** das amostras
- Accuracy: 15.58%
- F1 macro: 0.09

**An√°lise do History:**
- √âpoca 0 (frozen backbone): F1=0.4651 ‚úÖ Melhor performance
- √âpocas 1-7: Est√°vel ~0.44-0.46
- **√âpoca 8:** **COLAPSO** - F1=0.3439, Acc=0.3868 ‚ùå
- √âpocas 9-29: Nunca recuperou (~0.33-0.37)

### Causa Identificada

**Catastrophic Forgetting Severo** ao unfreeze do backbone (√©poca 7‚Üí8):
- Backbone Stage 1 features incompat√≠veis com Stage 2 task
- Unfreezing destruiu features aprendidas durante frozen training
- Consistente com documentado em `docs_v6/01_problema_negative_transfer.md`

### Impacto

üö´ **BLOQUEIA Experimento 10 (Confusion-Based Noise Injection)**
- Exp 10 requer confusion matrix realista do Stage 2
- Com modelo colapsado, matriz √© trivial (tudo prediz uma classe)
- Noise injection seria in√∫til

‚ö†Ô∏è **INVALIDA Experimento 09?**
- Se Stage 2 j√° estava colapsado durante pipeline evaluation:
  * Stage 3 recebeu inputs n√£o-diversificados (s√≥ RECT ou s√≥ SPLIT)
  * Resultados (45.86% accuracy) podem estar incorretos
  * **NECESS√ÅRIO:** Re-avaliar pipeline com Stage 2 funcional

---

## üéØ PLANO DE A√á√ÉO REVISADO (13-18/10/2025)

### Op√ß√£o A: Usar Modelo Frozen (RECOMENDADO - 1 dia) ‚≠ê

**Fundamenta√ß√£o:**
- √âpoca 0 (frozen) tinha F1=0.4651 ‚úÖ Melhor que unfrozen
- Script 004 foi projetado para salvar checkpoint frozen
- Unfreezing causou colapso ‚Üí **n√£o usar unfrozen**

**Protocolo:**
1. **Localizar checkpoint frozen (√©poca 0)** - 10 min
   ```bash
   # Verificar se existe stage2_model_block16_ep0.pt
   ls -lh pesquisa_v6/logs/v6_experiments/stage2/
   ```

2. **Se N√ÉO existe, retreinar apenas √©poca 0** - 30 min
   ```bash
   python3 pesquisa_v6/scripts/004_train_stage2_redesigned.py \
     --dataset-dir pesquisa_v6/v6_dataset/block_16 \
     --epochs 1 \
     --batch-size 128 \
     --output-dir pesquisa_v6/logs/v6_experiments/stage2_frozen \
     --device cuda \
     --save-every-epoch  # NOVO argumento
   ```

3. **Validar modelo frozen** - 15 min
   ```bash
   python3 pesquisa_v6/scripts/009_analyze_stage2_confusion.py \
     --stage2-model pesquisa_v6/logs/v6_experiments/stage2_frozen/stage2_model_ep0.pt \
     --dataset-dir pesquisa_v6/v6_dataset/block_16 \
     --device cuda
   ```
   
   **Esperado:** F1 ~0.46-0.47, accuracy ~48-49%

4. **Re-avaliar Pipeline Experimento 09** - 30 min
   ```bash
   python3 pesquisa_v6/scripts/008_run_pipeline_eval_v6.py \
     --stage1-model pesquisa_v6/logs/v6_experiments/stage1/stage1_model_best.pt \
     --stage2-model pesquisa_v6/logs/v6_experiments/stage2_frozen/stage2_model_ep0.pt \
     --stage3-rect-model pesquisa_v6/logs/.../stage3_rect_robust.pt \
     --stage3-ab-models <ensemble> \
     --output-dir pesquisa_v6/logs/v6_experiments/pipeline_eval_frozen_s2
   ```
   
   **Verificar:** Accuracy ‚âà 45.86% (Exp09) ou melhorou?

5. **Prosseguir Experimento 10** - 3 dias
   - Usar confusion matrix do modelo frozen
   - Implementar confusion-based noise injection
   - Retreinar Stage 3 com noise realista

**Cronograma:**
- **14/10 (Segunda):** Retreinar Stage 2 frozen + validar + re-avaliar pipeline
- **15/10 (Ter√ßa):** Implementar confusion-based labels
- **16-17/10 (Quarta-Quinta):** Retreinar Stage 3 com noise
- **18/10 (Sexta):** Avalia√ß√£o final e decis√£o

**Ganho esperado:** +1.5-2.5pp (45.86% ‚Üí 47.5-48.5%)

---

### Op√ß√£o B: Retreinar Stage 2 Completo (2-3 dias)

**Fundamenta√ß√£o:**
- Implementar salvamento de checkpoints a cada √©poca
- Monitorar F1 por classe durante treinamento
- Adicionar early stopping baseado em F1 macro (n√£o loss)

**Modifica√ß√µes no Script 004:**
```python
# 1. Salvar checkpoint a cada √©poca
if (epoch + 1) % 1 == 0:
    save_checkpoint(
        model, optimizer, epoch,
        f'stage2_model_ep{epoch}.pt'
    )

# 2. Early stopping baseado em F1
best_f1 = 0
patience = 10
patience_counter = 0

for epoch in range(epochs):
    val_f1 = validate_epoch(...)
    
    if val_f1 > best_f1:
        best_f1 = val_f1
        patience_counter = 0
        save_checkpoint(model, 'best')
    else:
        patience_counter += 1
    
    if patience_counter >= patience:
        print(f"Early stopping at epoch {epoch}")
        break

# 3. Monitorar F1 por classe
for i, class_name in enumerate(['SPLIT', 'RECT', 'AB']):
    f1_class = f1_score(y_true, y_pred, labels=[i], average='macro')
    print(f"  {class_name}: F1={f1_class:.4f}")
```

**Cronograma:**
- **14/10:** Modificar Script 004 com melhorias (2h)
- **14/10:** Retreinar Stage 2 com monitoring (2h)
- **15/10:** Validar melhor checkpoint (30min)
- **15/10:** An√°lise confusion matrix (30min)
- **16-17/10:** Experimento 10 (Confusion-Based Noise)
- **18/10:** Avalia√ß√£o e decis√£o

**Risco:** Pode n√£o resolver catastrophic forgetting (√© problema arquitetural)

---

### Op√ß√£o C: Pular Exp 10 ‚Üí Ir Direto para Train-with-Predictions (3 dias)

**Fundamenta√ß√£o:**
- Confusion-based noise √© aproxima√ß√£o de train-with-predictions
- Se vamos usar predi√ß√µes reais, melhor usar direto (n√£o confusion matrix)
- Heigold et al. (2016): Treinar com predi√ß√µes do modelo upstream

**Protocolo:**
```python
# 1. Gerar predi√ß√µes Stage 2 em tempo real
class TrainWithPredictionsDataset(Dataset):
    def __init__(self, stage2_model, stage3_dataset):
        self.stage2_model = stage2_model
        self.stage3_dataset = stage3_dataset
    
    def __getitem__(self, idx):
        block, gt_label, qp = self.stage3_dataset[idx]
        
        # Computar predi√ß√£o Stage 2 (frozen, sem grad)
        with torch.no_grad():
            stage2_logits = self.stage2_model(block.unsqueeze(0))
            stage2_pred = torch.argmax(stage2_logits, dim=1).item()
        
        # 75% usa GT, 25% usa predi√ß√£o Stage 2
        if random.random() < 0.75:
            return block, gt_label, qp  # Clean
        else:
            # Mapear predi√ß√£o Stage 2 ‚Üí Stage 3 labels
            mapped_label = map_stage2_to_stage3(stage2_pred, head='RECT')
            return block, mapped_label, qp  # Noisy (real prediction)
```

**Vantagens:**
- Noise √© **exatamente** o que Stage 3 ver√° em pipeline real
- N√£o depende de confusion matrix (robusta a Stage 2 colapsado)
- Mais pr√≥ximo de "online learning" (adapta a predi√ß√µes reais)

**Desvantagens:**
- Mais complexo de implementar
- Custo computacional maior (forward pass Stage 2 durante treinamento)

**Cronograma:**
- **14/10:** Implementar TrainWithPredictionsDataset (4h)
- **15/10:** Validar implementa√ß√£o (2h)
- **16-17/10:** Retreinar Stage 3 RECT e AB (1.5d)
- **18/10:** Avalia√ß√£o e decis√£o

**Ganho esperado:** +1.0-2.0pp (experimental, sem baseline na literatura para video codecs)

---

## üéØ DECIS√ÉO RECOMENDADA

### Primeira Prioridade: Op√ß√£o A (Usar Modelo Frozen) ‚≠ê

**Raz√µes:**
1. ‚úÖ **Mais r√°pido** (1 dia vs 2-3 dias)
2. ‚úÖ **Menor risco** (modelo frozen j√° provou F1=0.4651)
3. ‚úÖ **Valida√ß√£o cient√≠fica** (confirma hip√≥tese de que frozen > unfrozen)
4. ‚úÖ **Mant√©m cronograma** (Exp 10 inicia 15/10)

**Se Op√ß√£o A falhar** (modelo frozen n√£o dispon√≠vel e retreino frozen tamb√©m colapsa):
‚Üí Tentar **Op√ß√£o C** (Train-with-Predictions)
‚Üí Pular Op√ß√£o B (retreinar completo √© alto custo, baixo ganho esperado)

---

## üìù Pr√≥xima A√ß√£o Imediata (HOJE - 13/10/2025 √† noite)

### 1. Verificar Exist√™ncia de Checkpoint Frozen üî¥ URGENTE

```bash
cd /home/chiarorosa/CNN_AV1
ls -lh pesquisa_v6/logs/v6_experiments/stage2/ | grep -E "ep[0-9]|frozen"
```

**Se encontrar `stage2_model_ep0.pt` ou similar:**
‚úÖ Executar Script 009 nele e validar F1 ~0.46

**Se N√ÉO encontrar:**
‚ö†Ô∏è Retreinar 1 √©poca frozen amanh√£ (14/10 manh√£, 30 min)

### 2. Atualizar Documenta√ß√£o üü°

- ‚úÖ PROBLEMA_CRITICO_STAGE2.md criado
- ‚úÖ PROXIMOS_PASSOS.md atualizado
- ‚è≥ Criar `docs_v6/10_stage2_collapse_analysis.md` (PhD-level)

### 3. Push das Mudan√ßas üü°

```bash
git add pesquisa_v6/PROXIMOS_PASSOS.md
git commit -m "docs: Atualizar PROXIMOS_PASSOS com Op√ß√£o A/B/C p√≥s-diagn√≥stico Stage 2"
git push origin main
```

---

## üóìÔ∏è Cronograma Revisado (14-20/10/2025)

| Data | Atividade | Dura√ß√£o | Status |
|------|-----------|---------|--------|
| **13/10 (Domingo)** | Script 009 + Diagn√≥stico Stage 2 | 4h | ‚úÖ COMPLETO |
| **14/10 (Segunda) AM** | Retreinar Stage 2 frozen (1 √©poca) | 30min | üî¥ PR√ìXIMO |
| **14/10 (Segunda) PM** | Validar frozen + Re-avaliar pipeline | 1h | üî¥ PR√ìXIMO |
| **15/10 (Ter√ßa)** | Implementar confusion-based labels | 1d | ‚è≥ |
| **16-17/10 (Qua-Qui)** | Retreinar Stage 3 com confusion noise | 1.5d | ‚è≥ |
| **18/10 (Sexta)** | Avalia√ß√£o Exp 10 + Checkpoint decis√£o | 0.5d | ‚è≥ |
| **19-20/10 (S√°b-Dom)** | Buffer para ajustes / Exp 10.1-10.2 | 2d | ‚è≥ |

**Meta Final:** Accuracy ‚â•48.0% at√© 20/10/2025

---

## üìñ ARQUIVADO: Plano Original Experimento 10 (Pr√©-Descoberta)

<details>
<summary>Clique para expandir cronograma original (mantido para registro hist√≥rico)</summary>

## üéØ Experimento 10: Confusion-Based Noise Injection

---

## üìä Estado Atual do Projeto

### Experimentos Completos

| # | Experimento | Status | Resultado | Doc |
|---|-------------|--------|-----------|-----|
| 01-08 | Pipeline V6 Baseline | ‚úÖ | Accuracy=47.66% (-0.34pp da meta) | `05_avaliacao_pipeline_completo.md` |
| **09** | **Noise Injection (Random)** | ‚úÖ | Accuracy=45.86% (-1.80pp), Cascade error -28pp | `09_noise_injection_stage3.md` |

### Descobertas Cient√≠ficas (Experimento 09)

1. ‚úÖ **Hip√≥tese H3.1 VALIDADA:** Distribution Shift √© causa raiz do erro cascata
2. ‚úÖ **Noise Injection funciona:** Reduziu cascade error em 28-56pp
3. ‚úÖ **2 classes recuperadas:** HORZ 0%‚Üí23.94%, VERT_A 0%‚Üí15.25%
4. ‚ö†Ô∏è **Trade-off confirmado:** Robustez ‚Üë, Accuracy ‚Üì
5. ‚úÖ **Bug cr√≠tico descoberto:** IndexError em multi-dataset sampling

### Problema Remanescente

> "Noise injection com **labels aleat√≥rios** melhora robustez mas degrada accuracy. Precisamos de noise mais realista baseado em **erros reais do Stage 2**."

**Gap atual:** Accuracy 45.86% vs meta 48.0% = **-2.14pp**

---

## üéØ Experimento 10: Confusion-Based Noise Injection

### Objetivo

Substituir labels aleat√≥rios por distribui√ß√£o de confus√£o real do Stage 2 para melhorar trade-off robustez/accuracy.

**Meta:** Accuracy ‚â•48.0% mantendo ganhos de robustez

### Fundamenta√ß√£o Te√≥rica

- **Heigold et al. (2016):** Train-with-predictions reduz cascade error (usado em Google Translate)
- **Hendrycks et al. (2019):** Noise realista > noise uniforme
- **Natarajan et al. (2013):** Distribui√ß√£o de noise importa para robustez

### Hip√≥tese H3.2

> "Treinar Stage 3 com noise baseado em **confus√£o real** do Stage 2 (n√£o aleat√≥rio) melhorar√° accuracy mantendo robustez."

**Evid√™ncia:** 
- Exp09 provou que noise injection funciona (+28pp cascade error)
- Mas labels aleat√≥rios causaram trade-off negativo (-1.80pp accuracy)
- Stage 2 tem padr√µes espec√≠ficos de erro (RECT‚ÜîAB confus√£o esperada ~30-35%)

---

## üìÖ Cronograma Experimento 10

### Fase 1: An√°lise de Confus√£o (0.5 dia - 14/10)

**Script 009:** `pesquisa_v6/scripts/009_analyze_stage2_confusion.py`

**Objetivo:** Computar matriz de confus√£o real do Stage 2

**Protocolo:**
```python
# 1. Carregar Stage 2 frozen model (epoch 8)
model = torch.load('logs/v6_experiments/stage2/stage2_model_best.pt')

# 2. Inferir validation set completo (38,256 samples)
predictions, ground_truths = [], []
for batch in val_dataloader:
    preds = model(batch)
    predictions.append(preds)
    ground_truths.append(batch.labels)

# 3. Computar confusion matrix RECT vs AB
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(ground_truths, predictions)

# 4. Extrair probabilidades de erro
confusion_probs = {
    "RECT": {
        "AB": cm[RECT, AB] / cm[RECT].sum(),
        "SPLIT": cm[RECT, SPLIT] / cm[RECT].sum(),
        "correct": cm[RECT, RECT] / cm[RECT].sum()
    },
    "AB": {
        "RECT": cm[AB, RECT] / cm[AB].sum(),
        "SPLIT": cm[AB, SPLIT] / cm[AB].sum(),
        "correct": cm[AB, AB] / cm[AB].sum()
    }
}

# 5. Salvar como JSON
import json
with open('confusion_matrix_stage2.json', 'w') as f:
    json.dump(confusion_probs, f, indent=2)
```

**Output esperado:**
```json
{
  "RECT": {
    "AB": 0.35,
    "SPLIT": 0.12,
    "correct": 0.53
  },
  "AB": {
    "RECT": 0.28,
    "SPLIT": 0.15,
    "correct": 0.57
  },
  "SPLIT": {
    "RECT": 0.20,
    "AB": 0.18,
    "correct": 0.62
  }
}
```

**Tempo:** 4 horas (2h impl + 1h exec + 1h an√°lise)

---

### Fase 2: Implementa√ß√£o Confusion-Based (1 dia - 15/10)

**Modificar Scripts 005 e 006:**

```python
class NoisyDataset(Dataset):
    def __init__(self, clean_dataset, noise_datasets, noise_ratio=0.25, 
                 confusion_matrix=None):  # ‚Üê NOVO
        self.confusion_matrix = confusion_matrix
        # ... resto igual ...
    
    def __getitem__(self, idx):
        if idx < self.clean_size:
            return self.clean_dataset[self.clean_indices[idx]]
        else:
            noise_idx = idx - self.clean_size
            dataset_idx = noise_idx % len(self.noise_datasets)
            
            local_idx = noise_idx // len(self.noise_datasets)
            local_idx = local_idx % len(self.noise_datasets[dataset_idx])
            sample_idx = self.noise_datasets[dataset_idx][local_idx]
            
            block, _, qp = sample_idx
            
            # ‚ùå ANTES (labels aleat√≥rios):
            # random_label = torch.randint(0, 2, (1,)).item()
            
            # ‚úÖ DEPOIS (confusion-based):
            noise_source = self.noise_sources[dataset_idx]  # "AB" ou "SPLIT"
            confusion_probs = self.confusion_matrix[noise_source]
            
            # Exemplo: noise_source="AB", confusion_probs={"HORZ": 0.6, "VERT": 0.4}
            labels = list(confusion_probs.keys())
            probs = list(confusion_probs.values())
            random_label = np.random.choice(len(labels), p=probs)
            
            return block, random_label, qp
```

**Argumentos CLI:**
```python
parser.add_argument('--confusion-matrix', type=str, 
                    help='Path to confusion matrix JSON')
```

**Tempo:** 6 horas (4h impl + 2h test)

---

### Fase 3: Retreino com Confusion-Based Noise (1.5 dia - 16-17/10)

**Stage 3-RECT Robust v2:**
```bash
python3 pesquisa_v6/scripts/005_train_stage3_rect.py \
  --dataset-dir pesquisa_v6/v6_dataset_stage3/RECT/block_16 \
  --noise-injection 0.25 \
  --noise-sources AB SPLIT \
  --confusion-matrix pesquisa_v6/logs/v6_experiments/confusion_matrix_stage2.json \
  --epochs 30 \
  --batch-size 128 \
  --output-dir pesquisa_v6/logs/v6_experiments/stage3_rect_robust_v2 \
  --device cuda \
  --stage2-model pesquisa_v6/logs/v6_experiments/stage2/stage2_model_best.pt
```

**Stage 3-AB Robust v2:**
```bash
python3 pesquisa_v6/scripts/006_train_stage3_ab_fgvc.py \
  --dataset_dir pesquisa_v6/v6_dataset_stage3/AB/block_16 \
  --noise-injection 0.25 \
  --noise-sources RECT SPLIT \
  --confusion-matrix pesquisa_v6/logs/v6_experiments/confusion_matrix_stage2.json \
  --phase1_epochs 5 \
  --phase2_epochs 25 \
  --batch_size 128 \
  --output_dir pesquisa_v6/logs/v6_experiments/stage3_ab_robust_v2 \
  --stage2_model pesquisa_v6/logs/v6_experiments/stage2/stage2_model_best.pt
```

**Tempo:** 12 horas (6h RECT + 6h AB)

---

### Fase 4: Avalia√ß√£o e An√°lise (0.5 dia - 18/10)

**Pipeline Evaluation:**
```bash
python3 pesquisa_v6/scripts/008_run_pipeline_eval_v6.py \
  --dataset-dir pesquisa_v6/v6_dataset/block_16 \
  --stage1-model pesquisa_v6/logs/v6_experiments/stage1/stage1_model_best.pt \
  --stage2-model pesquisa_v6/logs/v6_experiments/stage2/stage2_model_best.pt \
  --stage3-rect-model pesquisa_v6/logs/v6_experiments/stage3_rect_robust_v2/stage3_rect_model_best.pt \
  --stage3-ab-models \
    pesquisa_v6/logs/v6_experiments/stage3_ab_robust_v2/stage3_ab_fgvc_best.pt \
    pesquisa_v6/logs/v6_experiments/stage3_ab_robust_v2/stage3_ab_fgvc_best.pt \
    pesquisa_v6/logs/v6_experiments/stage3_ab_robust_v2/stage3_ab_fgvc_best.pt \
  --stage1-threshold 0.45 \
  --output-dir pesquisa_v6/logs/v6_experiments/pipeline_eval_robust_v2 \
  --device cuda \
  --batch-size 256
```

**An√°lise Comparativa:**
```python
# Comparar:
# - Baseline: 47.66%
# - Noise Random (Exp09): 45.86%
# - Noise Confusion (Exp10): ???

# M√©tricas-chave:
# 1. Overall Accuracy (meta: ‚â•48.0%)
# 2. HORZ F1 (Exp09: 23.94%)
# 3. VERT_A F1 (Exp09: 15.25%)
# 4. Cascade error RECT/AB
# 5. Stage 3 standalone performance
```

**Tempo:** 4 horas (1h eval + 3h an√°lise + doc)

---

## üéØ Resultados Esperados (Exp10)

### Cen√°rio Otimista (70% probabilidade)

| M√©trica | Baseline | Noise Random (Exp09) | **Noise Confusion (Exp10)** | Meta |
|---------|----------|----------------------|-----------------------------|------|
| **Accuracy** | 47.66% | 45.86% | **48.5-49.2%** ‚úÖ | ‚â•48.0% |
| HORZ F1 | 0.00% | 23.94% | **28-35%** ‚úÖ | >20% |
| VERT_A F1 | 0.00% | 15.25% | **20-28%** ‚úÖ | >15% |
| Cascade RECT | -93% | -65% | **-55% a -45%** ‚úÖ | <-70% |
| Cascade AB | -94% | -38% | **-30% a -20%** ‚úÖ | <-50% |
| Stage 3-AB standalone | 24.50% | 19.41% | **22-25%** ‚úÖ | >20% |

**Ganho total:** +2.5-3.5pp vs Baseline, +2.6-3.3pp vs Exp09

### Cen√°rio Realista (25% probabilidade)

| M√©trica | Valor | Status |
|---------|-------|--------|
| Accuracy | 47.5-48.2% | ‚ö†Ô∏è Pr√≥ximo da meta |
| HORZ F1 | 25-28% | ‚úÖ Melhorou |
| VERT_A F1 | 18-22% | ‚úÖ Melhorou |

**A√ß√£o:** Testar grid search noise ratio (10-35%) ou ensemble real

### Cen√°rio Pessimista (5% probabilidade)

| M√©trica | Valor | Status |
|---------|-------|--------|
| Accuracy | <47.5% | ‚ùå N√£o melhorou |

**A√ß√£o:** Reavaliar estrat√©gia, considerar Train-with-Predictions (Exp11)

---

## üöÄ Experimentos Alternativos (Se Exp10 < 48%)

### Exp 10.1: Grid Search Noise Ratio (1 dia)

**Hip√≥tese:** 25% noise pode n√£o ser √≥timo

**Protocolo:**
```bash
for ratio in 0.10 0.15 0.20 0.25 0.30 0.35; do
  python3 005_train_stage3_rect.py \
    --noise-injection $ratio \
    --confusion-matrix confusion_matrix.json \
    --output-dir stage3_rect_noise${ratio}
done
```

**Ganho esperado:** +0.5-1.0pp

### Exp 10.2: Ensemble Real AB (1.5 dia)

**Problema:** Usado 1 modelo repetido 3x

**Solu√ß√£o:**
```bash
for seed in 42 123 456; do
  python3 006_train_stage3_ab_fgvc.py \
    --seed $seed \
    --confusion-matrix confusion_matrix.json \
    --output-dir stage3_ab_seed${seed}
done
```

**Ganho esperado:** +0.3-0.8pp

### Exp 11: Train-with-Predictions (3 dias)

**Conceito:** Substituir noise sint√©tico por predi√ß√µes reais do Stage 2

**Protocolo:**
```python
# Fase 1: Gerar predi√ß√µes Stage 2 (2h)
python3 generate_stage2_predictions.py \
  --stage2-model logs/.../stage2_model_best.pt \
  --dataset v6_dataset/block_16/train.pt \
  --output stage2_predictions_train.pt

# Fase 2: Treinar Stage 3 com predi√ß√µes (n√£o GT)
class PredictionAwareDataset(Dataset):
    def __init__(self, blocks, stage2_predictions):
        self.blocks = blocks
        self.labels = stage2_predictions  # ‚Üê Usa predi√ß√µes, n√£o GT
```

**Ganho esperado:** +1.0-2.0pp

**Custo:** 3 dias

---

## üìä Prioriza√ß√£o Final (14-20/10/2025)

| Exp | T√©cnica | Custo | Ganho | Prioridade | Data |
|-----|---------|-------|-------|------------|------|
| **10** | **Confusion-Based Noise** | **3d** | **+1.5-2.5pp** | üî¥üî¥üî¥ **PR√ìXIMO** | **14-17/10** |
| 10.1 | Grid Search Noise | 1d | +0.5-1.0pp | üî¥üî¥ Alta | 18/10 (se <48%) |
| 10.2 | Ensemble Real AB | 1.5d | +0.3-0.8pp | üî¥üî¥ Alta | 19-20/10 (se <48%) |
| 11 | Train-with-Predictions | 3d | +1.0-2.0pp | üî¥ M√©dia | 21-23/10 (se <47.5%) |

---

## ‚úÖ Checkpoint de Decis√£o (18/10/2025)

**Ap√≥s Exp10 completar:**

### Se Accuracy ‚â•48.0% ‚Üí ‚úÖ FINALIZAR Pipeline v6

**A√ß√µes:**
1. Documentar Exp10 em `docs_v6/10_confusion_based_noise.md`
2. Atualizar `PLANO_v6_Out.md` com resultados finais
3. Criar apresenta√ß√£o de resultados (slides)
4. Preparar artigo cient√≠fico (draft)
5. Avan√ßar para encoding speedup experiments

**Tempo:** 3-5 dias documenta√ß√£o

### Se 47.5% ‚â§ Accuracy < 48.0% ‚Üí ‚ö†Ô∏è OTIMIZA√á√ïES R√ÅPIDAS

**A√ß√µes:**
1. Exp 10.1: Grid search noise ratio (1 dia)
2. Exp 10.2: Ensemble real AB (1.5 dia)
3. Re-avaliar pipeline

**Tempo adicional:** 2.5 dias

### Se Accuracy < 47.5% ‚Üí ‚ùå REAVALIAR ESTRAT√âGIA

**A√ß√µes:**
1. Analisar por que Exp10 falhou
2. Considerar Exp11 (Train-with-Predictions) - 3 dias
3. Ou aceitar 47.5% como limite t√©cnico e documentar
4. Ou explorar arquiteturas alternativas (ViT, etc)

**Decis√£o cr√≠tica:** Investir mais tempo ou finalizar?

---

## üìù Pr√≥xima A√ß√£o Imediata (AMANH√É - 14/10/2025)

### Manh√£ (4h): Implementar Script 009

```bash
cd /home/chiarorosa/CNN_AV1/pesquisa_v6/scripts

# Criar script
# Conte√∫do: An√°lise de confus√£o Stage 2
# - Carregar modelo frozen
# - Inferir validation set
# - Computar confusion matrix
# - Salvar JSON

# Testar com 100 samples primeiro
python3 009_analyze_stage2_confusion.py --test
```

### Tarde (2h): Executar an√°lise completa

```bash
# Executar com dataset completo
python3 009_analyze_stage2_confusion.py \
  --stage2-model ../logs/v6_experiments/stage2/stage2_model_best.pt \
  --dataset ../v6_dataset/block_16/val.pt \
  --output ../logs/v6_experiments/confusion_matrix_stage2.json

# Validar output
python3 -c "
import json
with open('confusion_matrix_stage2.json') as f:
    cm = json.load(f)
    print('Confusion Matrix:')
    print(json.dumps(cm, indent=2))
    
    # Verificar somas
    for cls in cm:
        total = sum(cm[cls].values())
        print(f'{cls}: {total:.3f} (deve ser ~1.0)')
"
```

### An√°lise (2h): Documentar padr√µes

**Criar:** `docs_v6/10_confusion_analysis.md` (preliminar)

**Conte√∫do:**
- Matriz de confus√£o visualizada
- Principais confus√µes identificadas
- Hip√≥teses sobre causas (padr√µes visuais)
- Expectativa para Exp10

---

**Resumo:** Come√ßar Exp10 amanh√£ (14/10), completar em 3 dias, checkpoint de decis√£o em 18/10.

**Meta final:** Accuracy ‚â•48.0% at√© 20/10/2025.
